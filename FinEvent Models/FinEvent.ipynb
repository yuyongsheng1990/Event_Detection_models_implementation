{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58b839b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsettings:\\n    matplotlib==3.5.1\\n    networkx==2.6.3\\n    numpy==1.22.0\\n    pandas==1.3.5\\n    scikit-learn==1.0.1\\n    scipy==1.7.3\\n    torch==1.10.0\\n    torch-cluster==1.5.9\\n    torch-geometric==2.0.2\\n    torch-scatter==2.0.9\\n    torch-sparse==0.6.12\\n    torch-spline-conv==1.2.1\\n    tqdm==4.62.3\\n    dgl==0.4.3\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2022.10.6，复现FinEvent Model\n",
    "paper: from Reinforced, Incremental and Cross-lingual Event Detection From Social Messages\n",
    "github address: https://github.com/RingBDStack/FinEvent\n",
    "'''\n",
    "'''\n",
    "settings:\n",
    "    matplotlib==3.5.1\n",
    "    networkx==2.6.3\n",
    "    numpy==1.22.0\n",
    "    pandas==1.3.5\n",
    "    scikit-learn==1.0.1\n",
    "    scipy==1.7.3\n",
    "    torch==1.10.0\n",
    "    torch-cluster==1.5.9\n",
    "    torch-geometric==2.0.2\n",
    "    torch-scatter==2.0.9\n",
    "    torch-sparse==0.6.12\n",
    "    torch-spline-conv==1.2.1\n",
    "    tqdm==4.62.3\n",
    "    dgl==0.4.3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cec4d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import networkx as nx\n",
    "from scipy import sparse\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "project_path = os.path.abspath(os.path.dirname(os.getcwd()))  # # 获取上级路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b6e88b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27c2f2",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40212d7c",
   "metadata": {},
   "source": [
    "## step 1: load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "101b1f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis file generates the initial message features (please see Figure 1(b) and Section 3.2 of the paper for more details).\\nTo leverage the semantics in the data, we generate document feature for each message,\\nwhich is calculated as an average of the pre-trained word embeddings of all the words in the message\\nWe use the word embeddings pre-trained by en_core_web_lg, while other options, \\nsuch as word embeddings pre-trained by BERT, are also applicable.\\nTo leverage the temporal information in the data, we generate temporal feature for each message,\\nwhich is calculated by encoding the times-tamps: we convert each timestamp to OLE date, \\nwhose fractional and integral components form a 2-d vector.\\nThe initial feature of a message is the concatenation of its document feature and temporal feature.\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the initial features for the messages\n",
    "'''\n",
    "This file generates the initial message features (please see Figure 1(b) and Section 3.2 of the paper for more details).\n",
    "To leverage the semantics in the data, we generate document feature for each message,\n",
    "which is calculated as an average of the pre-trained word embeddings of all the words in the message\n",
    "We use the word embeddings pre-trained by en_core_web_lg, while other options, \n",
    "such as word embeddings pre-trained by BERT, are also applicable.\n",
    "To leverage the temporal information in the data, we generate temporal feature for each message,\n",
    "which is calculated by encoding the times-tamps: we convert each timestamp to OLE date, \n",
    "whose fractional and integral components form a 2-d vector.\n",
    "The initial feature of a message is the concatenation of its document feature and temporal feature.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8000e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_lg  # spacy提供的预训练语言模型，将文本标记化已生成doc对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a03ac16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7794e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = project_path + '/data/FinEvent_datasets/raw dataset/'\n",
    "save_path = project_path + '/result/FinEvent result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6adc640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\GNN_Event_Detection_models/data/FinEvent_datasets/raw dataset/\n",
      "D:\\PycharmProjects\\GNN_Event_Detection_models/result/FinEvent result/\n"
     ]
    }
   ],
   "source": [
    "print(load_path)\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79eebee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data.\n",
      "Data converted to dataframe.\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "p_part1 = load_path + '68841_tweets_multiclasses_filtered_0722_part1.npy'\n",
    "p_part2 = load_path + '68841_tweets_multiclasses_filtered_0722_part2.npy'\n",
    "# Python 中的 pickle 用于在保存到磁盘文件或从磁盘文件读取之前，对对象进行序列化和反序列化\n",
    "df_np_part1 = np.load(p_part1, allow_pickle=True)  # ndarray, (35000, 16) allow_pickle, Allow loading pickled object arrays stored in npy files\n",
    "df_np_part2 = np.load(p_part2, allow_pickle=True)  # ndarray, (33841, 16)\n",
    "df = np.concatenate((df_np_part1, df_np_part2),axis=0) # 按行拼接; ndarray, (68841, 16)\n",
    "print('loaded data.')\n",
    "df = pd.DataFrame(data=df, columns=['event_id','tweet_id','text','user_id','created_at','user_loc','place_type',\n",
    "                                      'place_full_name','place_country_code','hashtags','user_mentions','image_urls',\n",
    "                                      'entities','words','filtered_words','sampled_words'])\n",
    "print('Data converted to dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93787f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort date by time\n",
    "df = df.sort_values(by='created_at').reset_index(drop=True)\n",
    "\n",
    "df['date'] = [d.date() for d in df['created_at']]\n",
    "# 因为graph太大，爆了内存，所以取4天的twitter data做demo，后面用nci server\n",
    "init_day = df.loc[0, 'date']\n",
    "df_4days = df[(df['date']>= init_day) & (df['date']<= init_day + datetime.timedelta(days=3))].reset_index()  # （11971， 18）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f05e316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11971, 18)\n",
      "89\n",
      "10905\n"
     ]
    }
   ],
   "source": [
    "print(df_4days.shape)\n",
    "print(df_4days.event_id.nunique())\n",
    "print(df_4days.user_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e7cbfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>event_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>place_type</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_country_code</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>image_urls</th>\n",
       "      <th>entities</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>sampled_words</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "      <td>255819992157786112</td>\n",
       "      <td>HipHop awards bout to be live!!</td>\n",
       "      <td>250870763</td>\n",
       "      <td>2012-10-10 00:00:13</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[award, live, bout, hiphop]</td>\n",
       "      <td>[award, live, bout, hiphop]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>394</td>\n",
       "      <td>255820118095978496</td>\n",
       "      <td>HIPHOP AWARDS TIME!</td>\n",
       "      <td>28026779</td>\n",
       "      <td>2012-10-10 00:00:43</td>\n",
       "      <td>SoundCloud/RaRaSupaStar</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[HIPHOP, AWARDS, time]</td>\n",
       "      <td>[hiphop, awards, time]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "      <td>255820147489636353</td>\n",
       "      <td>Bet hiphop awards</td>\n",
       "      <td>566825483</td>\n",
       "      <td>2012-10-10 00:00:50</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Bet, GPE)]</td>\n",
       "      <td>[award, bet, hiphop]</td>\n",
       "      <td>[award, bet, hiphop]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>394</td>\n",
       "      <td>255820164023595008</td>\n",
       "      <td>BET HipHop awards is on!!!</td>\n",
       "      <td>197834311</td>\n",
       "      <td>2012-10-10 00:00:54</td>\n",
       "      <td>Saint Lucia ☀️🌴🇱🇨</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[HipHop, BET, award]</td>\n",
       "      <td>[hiphop, bet, award]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>394</td>\n",
       "      <td>255820180884701184</td>\n",
       "      <td>Watchin Da BET Hiphop Awards</td>\n",
       "      <td>439490861</td>\n",
       "      <td>2012-10-10 00:00:58</td>\n",
       "      <td>Michigan, USA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Hiphop, Watchin, Awards, Da, BET]</td>\n",
       "      <td>[hiphop, watchin, awards, da, bet]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index event_id            tweet_id                             text  \\\n",
       "0      0      394  255819992157786112  HipHop awards bout to be live!!   \n",
       "1      1      394  255820118095978496              HIPHOP AWARDS TIME!   \n",
       "2      2      394  255820147489636353                Bet hiphop awards   \n",
       "3      3      394  255820164023595008       BET HipHop awards is on!!!   \n",
       "4      4      394  255820180884701184     Watchin Da BET Hiphop Awards   \n",
       "\n",
       "     user_id          created_at                 user_loc place_type  \\\n",
       "0  250870763 2012-10-10 00:00:13                                       \n",
       "1   28026779 2012-10-10 00:00:43  SoundCloud/RaRaSupaStar              \n",
       "2  566825483 2012-10-10 00:00:50                                       \n",
       "3  197834311 2012-10-10 00:00:54        Saint Lucia ☀️🌴🇱🇨              \n",
       "4  439490861 2012-10-10 00:00:58            Michigan, USA              \n",
       "\n",
       "  place_full_name place_country_code hashtags user_mentions image_urls  \\\n",
       "0                                          []            []         []   \n",
       "1                                          []            []         []   \n",
       "2                                          []            []         []   \n",
       "3                                          []            []         []   \n",
       "4                                          []            []         []   \n",
       "\n",
       "       entities                               words  \\\n",
       "0            []         [award, live, bout, hiphop]   \n",
       "1            []              [HIPHOP, AWARDS, time]   \n",
       "2  [(Bet, GPE)]                [award, bet, hiphop]   \n",
       "3            []                [HipHop, BET, award]   \n",
       "4            []  [Hiphop, Watchin, Awards, Da, BET]   \n",
       "\n",
       "                       filtered_words sampled_words        date  \n",
       "0         [award, live, bout, hiphop]            []  2012-10-10  \n",
       "1              [hiphop, awards, time]            []  2012-10-10  \n",
       "2                [award, bet, hiphop]            []  2012-10-10  \n",
       "3                [hiphop, bet, award]            []  2012-10-10  \n",
       "4  [hiphop, watchin, awards, da, bet]            []  2012-10-10  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4days.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5819f595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple orange'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(['apple','orange'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f9468b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.0110998 , -1.1696801 , -1.836925  ,  3.62435   , -0.38999498,\n",
       "       -4.14575   , -2.7551    ,  4.432     , -3.6439    ,  1.56774   ,\n",
       "        5.17155   , -2.1609    , -3.04495   ,  1.418985  ,  0.385655  ,\n",
       "       -1.35931   ,  0.6796    , -1.65807   ,  2.4508    , -3.6395502 ,\n",
       "       -1.361265  ,  3.3911    , -2.3505502 , -2.64425   , -1.4074149 ,\n",
       "       -2.9309    , -2.8713    ,  0.45424998,  0.494435  ,  1.3266001 ,\n",
       "       -1.1863351 , -0.805145  , -1.74835   , -2.51085   ,  1.7619    ,\n",
       "       -1.5734999 ,  2.69375   ,  2.93885   ,  2.39905   , -1.84745   ,\n",
       "        1.80935   ,  0.02054995, -0.08278999,  1.805665  ,  1.297785  ,\n",
       "        4.19905   ,  1.0158501 , -0.53619003,  0.36874998,  0.88796496,\n",
       "        1.3213301 ,  0.95765996,  0.53971505, -1.07363   , -2.0834498 ,\n",
       "        1.16805   ,  0.513239  ,  1.7584    ,  2.365     ,  0.45940998,\n",
       "        1.114205  ,  2.19576   , -0.65239   , -0.8655875 , -1.4635    ,\n",
       "       -1.12686   , -0.654125  , -5.0572    ,  1.706955  ,  0.7140905 ,\n",
       "        0.18399003,  1.214605  , -0.55937   , -0.03608499,  1.72783   ,\n",
       "        1.5109501 , -3.2747498 , -2.4126    ,  2.8046498 , -0.69925   ,\n",
       "        0.08292501,  1.4252    , -1.40222   , -0.161405  ,  1.9577    ,\n",
       "        2.92315   ,  3.92705   ,  2.37919   , -3.4520998 ,  1.21405   ,\n",
       "       -0.72452   ,  2.89295   ,  3.7947998 , -2.253     ,  0.39468   ,\n",
       "       -0.74540997,  4.6324997 , -3.07635   , -0.97773004, -2.5821    ,\n",
       "       -1.0297451 , -1.5957999 ,  3.0032    , -3.8875499 ,  0.983415  ,\n",
       "        4.0956    , -2.3144    ,  1.100465  , -2.66325   ,  0.755045  ,\n",
       "       -0.945415  , -1.6505    ,  1.4755    , -0.088165  , -0.92186004,\n",
       "        0.83010995,  2.4917998 , -4.87885   ,  0.368615  , -2.51565   ,\n",
       "       -1.196195  ,  0.345475  , -3.4098    ,  0.98731005, -1.8608999 ,\n",
       "       -1.7764101 , -0.792635  , -4.7539    ,  5.4427004 , -1.714245  ,\n",
       "       -2.767     ,  2.11765   ,  2.9257002 , -0.9242001 ,  1.317845  ,\n",
       "        0.6444555 , -2.2532501 , -3.84      ,  1.241415  , -1.1724349 ,\n",
       "       -0.8314105 ,  1.2356    , -0.5785445 , -0.124265  , -1.6407499 ,\n",
       "       -2.37737   ,  0.23260003, -0.49001503,  0.91589   , -0.337985  ,\n",
       "       -1.2370551 ,  3.1024    , -1.47059   ,  0.3114925 , -1.09988   ,\n",
       "        2.1496    ,  4.91815   ,  1.0532701 , -0.13689995, -1.3814449 ,\n",
       "       -0.83028495, -2.74435   ,  0.575295  , -0.07805   ,  0.349875  ,\n",
       "       -0.70633   , -1.8892545 ,  3.17795   , -0.34900498, -0.97155   ,\n",
       "       -2.4014502 , -0.308645  ,  1.5397    ,  2.39539   , -3.4741    ,\n",
       "        0.742038  ,  0.36888   , -1.424945  ,  2.16179   , -1.774455  ,\n",
       "       -3.6488001 ,  1.2621999 , -3.5694    , -0.45152003, -1.023715  ,\n",
       "       -3.16575   ,  1.47891   , -0.366     ,  2.3464    , -1.9343    ,\n",
       "       -0.066103  , -1.373405  , -0.16980004,  0.34351003,  0.45071998,\n",
       "       -0.4579    , -3.0018501 ,  2.3866    ,  2.66955   ,  0.66981   ,\n",
       "        0.246895  , -1.1091499 ,  1.7041001 , -2.36015   , -0.343955  ,\n",
       "        2.025655  , -1.59215   ,  1.84497   ,  1.85645   ,  0.01043001,\n",
       "        2.21935   , -0.76988   , -0.7163283 ,  3.43885   ,  2.9425    ,\n",
       "       -1.69526   ,  4.17135   , -0.775475  , -1.14217   ,  0.86177504,\n",
       "        2.9757    , -0.511155  , -2.33185   ,  1.3068    ,  2.4316    ,\n",
       "       -2.1859    , -1.322525  ,  3.00665   ,  2.26965   ,  3.3906999 ,\n",
       "        0.04269999, -1.9162251 ,  0.93624   ,  0.253317  , -4.1192503 ,\n",
       "        3.60775   , -2.28615   ,  4.163     , -0.11091504, -1.35395   ,\n",
       "        0.15709999, -0.45066503, -0.54945   ,  4.1812    , -0.940665  ,\n",
       "        2.8109999 , -1.23508   ,  0.18045002, -0.961135  , -4.4705    ,\n",
       "       -1.360445  ,  2.95925   , -1.6655099 , -1.434475  , -0.84205997,\n",
       "       -2.84745   , -0.60528   ,  5.0722504 , -2.9237    ,  0.1990025 ,\n",
       "       -2.34521   ,  2.42525   , -2.0008001 ,  2.011255  , -0.51383   ,\n",
       "        1.3772999 , -1.6201451 , -0.06687498, -4.8313    ,  0.36800003,\n",
       "        4.0598    ,  2.41745   ,  2.2585    , -0.456413  ,  0.44165003,\n",
       "       -3.7245002 ,  1.2915499 ,  0.19281998,  1.6036    , -0.82016   ,\n",
       "        1.929595  ,  0.439953  ,  2.9638002 , -0.4986975 ,  1.60965   ,\n",
       "       -1.9485999 , -1.72883   , -0.09885001, -2.4696    ,  2.35475   ,\n",
       "        0.04689997, -0.47034252,  1.7963    , -2.9976501 , -2.3356    ,\n",
       "        0.14620501,  3.59445   , -0.83054507,  0.06312001, -0.912935  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = en_core_web_lg.load()\n",
    "nlp(' '.join(['apple','orange'])).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8a51db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['award', 'live', 'bout', 'hiphop']),\n",
       "       list(['hiphop', 'awards', 'time']),\n",
       "       list(['award', 'bet', 'hiphop']), ...,\n",
       "       list(['election', 'watch', 'presentation']),\n",
       "       list(['anything', 'damascus', 'rock', 'kill', 'brother', 'co', 'parliament', 'get', 'man', 'anything', 'speaker', 'bombing']),\n",
       "       list(['not', 'cuz', 'afford', 'idk', 'country', 'can', 'whole', 'win', 'leave', 'take', 'fam', 'romney', 'could'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filtered_words.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9074551",
   "metadata": {},
   "source": [
    "### document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0abd390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the embeddings of all the documents in the dataframe\n",
    "# the embeddings of each document is an average of the pre-trained embeddings of all the words in it\n",
    "def documents_to_features(df):\n",
    "    nlp = en_core_web_lg.load()\n",
    "    '''\n",
    "    filtered_words: ['literature', 'nobel', 'prize', 'announce']\n",
    "    features, ndarray, (68841,)。其中，单个元素是300维的向量\n",
    "    [-7.0156753e-01 -2.4638350e+00  9.9222124e-01 -1.6435424e+00,  2.2959824e+00 -9.4725072e-02 ...]\n",
    "    '''\n",
    "    features = df.filtered_words.apply(lambda x: nlp(' '.join(x)).vector).values  # nlp生成300维向量；join函数将列表连接成字符串\n",
    "    return np.stack(features, axis=0)  # stack函数沿axis邻接数组序列"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb6b8b",
   "metadata": {},
   "source": [
    "### time featurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57876cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode one times-tamp\n",
    "# t_str: a string of format '2012-10-11 07:19:34'\n",
    "def extract_time_feature(t_str):\n",
    "    t = datetime.datetime.fromisoformat(str(t_str)) # 分别返回年月日时分秒列表\n",
    "    OLE_TIME_ZERO = datetime.datetime(1899, 12, 30)\n",
    "    delta = t - OLE_TIME_ZERO  # datetime.timedelta(days=41193, seconds=26374)\n",
    "    return [(float(delta.days)/10000.), (float(delta.seconds)/86400)] # 86400 seconds in day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed571763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the times-tamps of all the messages in the dateframe\n",
    "def df_to_t_features(df):\n",
    "    t_features = np.asarray([extract_time_feature(t_str) for t_str in df['created_at']])\n",
    "    return t_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc13c4",
   "metadata": {},
   "source": [
    "### combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4919b2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document features generated\n",
      "Time features generated.\n",
      "Concatenated document features and time features.\n",
      "Initial features saved.\n",
      "Initial features loaded.\n",
      "(11971, 302)\n"
     ]
    }
   ],
   "source": [
    "# 生成文档embedding\n",
    "d_features = documents_to_features(df_4days)\n",
    "print('Document features generated')\n",
    "\n",
    "# 生成时间特征days和seconds\n",
    "t_features = df_to_t_features(df_4days)  # ndarray,(11971, 2)\n",
    "print('Time features generated.')\n",
    "\n",
    "combined_features = np.concatenate((d_features, t_features), axis=1)  # （11971， 302）\n",
    "print('Concatenated document features and time features.')\n",
    "\n",
    "np.save(save_path + 'combined_features.npy', combined_features)\n",
    "print('Initial features saved.')\n",
    "\n",
    "combined_features = np.load(save_path + 'combined_features.npy')\n",
    "print('Initial features loaded.')\n",
    "print(combined_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d461187d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11971, 300)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93f075c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5251225 , -1.2804475 , -1.67361   , ..., -0.10845   ,\n",
       "        -1.2274101 , -1.1007351 ],\n",
       "       [-0.08792333, -0.6259634 , -0.9900033 , ..., -2.038623  ,\n",
       "        -1.2348766 ,  0.46889666],\n",
       "       [-0.7383423 , -2.3103633 , -1.5300802 , ...,  1.8419999 ,\n",
       "         0.25515997,  0.3208867 ],\n",
       "       ...,\n",
       "       [ 0.82871836,  1.8417288 , -1.7910568 , ..., -1.1083716 ,\n",
       "        -0.07446832,  0.07849339],\n",
       "       [-0.37493247, -0.04668879, -1.7778028 , ...,  0.10513129,\n",
       "         0.5673075 ,  0.60081255],\n",
       "       [-3.7216501 , -1.1870999 ,  3.4422648 , ..., -7.9503    ,\n",
       "        -1.2189649 , -4.237005  ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3ae0704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11971, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5323c7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.11920000e+00, 1.50462963e-04],\n",
       "       [4.11920000e+00, 4.97685185e-04],\n",
       "       [4.11920000e+00, 5.78703704e-04],\n",
       "       ...,\n",
       "       [4.11950000e+00, 9.96261574e-01],\n",
       "       [4.11950000e+00, 9.97430556e-01],\n",
       "       [4.11950000e+00, 9.99652778e-01]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c402ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11971, 302)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73a8ec6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.52512252e+00, -1.28044748e+00, -1.67360997e+00, ...,\n",
       "        -1.10073507e+00,  4.11920000e+00,  1.50462963e-04],\n",
       "       [-8.79233256e-02, -6.25963390e-01, -9.90003288e-01, ...,\n",
       "         4.68896657e-01,  4.11920000e+00,  4.97685185e-04],\n",
       "       [-7.38342285e-01, -2.31036329e+00, -1.53008020e+00, ...,\n",
       "         3.20886701e-01,  4.11920000e+00,  5.78703704e-04],\n",
       "       ...,\n",
       "       [ 8.28718364e-01,  1.84172881e+00, -1.79105675e+00, ...,\n",
       "         7.84933940e-02,  4.11950000e+00,  9.96261574e-01],\n",
       "       [-3.74932468e-01, -4.66887876e-02, -1.77780282e+00, ...,\n",
       "         6.00812554e-01,  4.11950000e+00,  9.97430556e-01],\n",
       "       [-3.72165012e+00, -1.18709993e+00,  3.44226480e+00, ...,\n",
       "        -4.23700523e+00,  4.11950000e+00,  9.99652778e-01]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec3b46",
   "metadata": {},
   "source": [
    "## step 2: construct message graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a07ad4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis file splits the Twitter dataset into 21 message blocks (please see Section 4.3 of the paper for more details), \\nuse the message blocks to construct heterogeneous social graphs (please see Figure 1(a) and Section 3.2 of the paper for more details) \\nand maps them into homogeneous message graphs (Figure 1(c)).\\nNote that:\\n# 1) We adopt the Latest Message Strategy (which is the most efficient and gives the strongest performance. See Section 4.4 of the paper for more details) here, \\n# as a consequence, each message graph only contains the messages of the date and all previous messages are removed from the graph;\\n# To switch to the All Message Strategy or the Relevant Message Strategy, replace 'G = construct_graph_from_df(incr_df)' with 'G = construct_graph_from_df(incr_df, G)' inside construct_incremental_dataset_0922().\\n# 2) For test purpose, when calling construct_incremental_dataset_0922(), set test=True, and the message blocks, as well as the resulted message graphs each will contain 100 messages.\\n# To use all the messages, set test=False, and the number of messages in the message blocks will follow Table. 4 of the paper.\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct incremental message graphs\n",
    "'''\n",
    "This file splits the Twitter dataset into 21 message blocks (please see Section 4.3 of the paper for more details), \n",
    "use the message blocks to construct heterogeneous social graphs (please see Figure 1(a) and Section 3.2 of the paper for more details) \n",
    "and maps them into homogeneous message graphs (Figure 1(c)).\n",
    "Note that:\n",
    "# 1) We adopt the Latest Message Strategy (which is the most efficient and gives the strongest performance. See Section 4.4 of the paper for more details) here, \n",
    "# as a consequence, each message graph only contains the messages of the date and all previous messages are removed from the graph;\n",
    "# To switch to the All Message Strategy or the Relevant Message Strategy, replace 'G = construct_graph_from_df(incr_df)' with 'G = construct_graph_from_df(incr_df, G)' inside construct_incremental_dataset_0922().\n",
    "# 2) For test purpose, when calling construct_incremental_dataset_0922(), set test=True, and the message blocks, as well as the resulted message graphs each will contain 100 messages.\n",
    "# To use all the messages, set test=False, and the number of messages in the message blocks will follow Table. 4 of the paper.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f00bb",
   "metadata": {},
   "source": [
    "### graph examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b2e59d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from scipy import sparse\n",
    "\n",
    "from time import time\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d845505",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "tweet_list = ['t_123', 't_456', 't_789']\n",
    "G.add_nodes_from(tweet_list)\n",
    "for i in tweet_list:\n",
    "    G.nodes[i]['tweet_id'] = True\n",
    "user_list = ['Sydney', 'Beijing', 'Melbourne']\n",
    "entity_list = ['me', 'bing', 'zhen']\n",
    "G.add_nodes_from(user_list)\n",
    "G.add_nodes_from(entity_list)\n",
    "\n",
    "for i in entity_list:\n",
    "    G.nodes[i]['entity_id'] = True\n",
    "for i in user_list:\n",
    "    G.nodes[i]['user_id'] = True\n",
    "G.add_edges_from([['t_123', 't_456'],['t_123', 't_789'], ['t_123', 'Sydney'], ['t_456', 'Melbourne'], ['t_456', 'Beijing']])\n",
    "G.add_edges_from([['t_123', 'me'], ['t_123', 'bing'], ['t_789', 'zhen']])\n",
    "G.nodes['t_123']['tweet_id'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4acf4b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw_networkx(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec4da07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_id和user_id结构关系\n",
    "tid_nodes = list(nx.get_node_attributes(G, 'tweet_id').keys())\n",
    "userid_nodes = list(nx.get_node_attributes(G, 'user_id').keys())\n",
    "all_nodes = list(G.nodes)\n",
    "indices_tid = [all_nodes.index(x) for x in tid_nodes]\n",
    "indices_userid = [all_nodes.index(x) for x in userid_nodes]\n",
    "A = nx.to_numpy_matrix(G)\n",
    "w_tid_userid = A[np.ix_(indices_tid, indices_userid)]\n",
    "s_w_tid_userid = sparse.csr_matrix(w_tid_userid)\n",
    "s_w_userid_tid = s_w_tid_userid.transpose()\n",
    "homo_s_w_tid_userid = s_w_tid_userid * s_w_userid_tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7482c677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 2., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homo_s_w_tid_userid.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2918594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_id和entity 结构关系\n",
    "tid_nodes = list(nx.get_node_attributes(G, 'tweet_id').keys())\n",
    "entity_nodes = list(nx.get_node_attributes(G, 'entity_id').keys())\n",
    "all_nodes = list(G.nodes)\n",
    "indices_tid = [all_nodes.index(x) for x in tid_nodes]\n",
    "indices_entityid = [all_nodes.index(x) for x in entity_nodes]\n",
    "A = nx.to_numpy_matrix(G)\n",
    "w_tid_userid = A[np.ix_(indices_tid, indices_entityid)]\n",
    "s_w_tid_userid = sparse.csr_matrix(w_tid_userid)\n",
    "s_w_userid_tid = s_w_tid_userid.transpose()\n",
    "homo_s_w_tid_entityid = s_w_tid_userid * s_w_userid_tid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a1430",
   "metadata": {},
   "source": [
    "### construct heterogeneous graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24f968f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>place_type</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_country_code</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>image_urls</th>\n",
       "      <th>entities</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>sampled_words</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>256292946331181056</td>\n",
       "      <td>Nobel prize in literature to be announced http...</td>\n",
       "      <td>47667947</td>\n",
       "      <td>2012-10-11 07:19:34</td>\n",
       "      <td>Munich, Germany</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[literature, Nobel, prize, announce]</td>\n",
       "      <td>[literature, nobel, prize, announce]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>256333064467279872</td>\n",
       "      <td>“@marvicleonen: Is it true that UP won UAAP ba...</td>\n",
       "      <td>67518107</td>\n",
       "      <td>2012-10-11 09:58:59</td>\n",
       "      <td>Philippines</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[28775032]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(UP, ORG), (Next year, DATE), (Dean, PERSON)]</td>\n",
       "      <td>[Dean, Sure, year, yan, na, \", basketball, tru...</td>\n",
       "      <td>[dean, sure, year, yan, na, basketball, true, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>256334302034399232</td>\n",
       "      <td>Congrats, Ateneo! Last na yan ha. Season 76 wi...</td>\n",
       "      <td>97449266</td>\n",
       "      <td>2012-10-11 10:03:54</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Ateneo, PERSON), (Season 76, PERSON)]</td>\n",
       "      <td>[yan, ☺, na, ha, different, last, Ateneo, cong...</td>\n",
       "      <td>[yan, na, ha, different, last, ateneo, congrat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>256335853738160128</td>\n",
       "      <td>\"@SMARTPromos: SMART never wants you to be lef...</td>\n",
       "      <td>405138197</td>\n",
       "      <td>2012-10-11 10:10:04</td>\n",
       "      <td>Lost in Dreamland</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[106915372]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(BIG, ORG), (BIG, ORG)]</td>\n",
       "      <td>[never, s, yan, next, na, thing, Ano, leave, t...</td>\n",
       "      <td>[never, yan, next, na, thing, ano, leave, that...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>256346272506712064</td>\n",
       "      <td>CCTV invite hints at Nobel literature prize fo...</td>\n",
       "      <td>197326414</td>\n",
       "      <td>2012-10-11 10:51:28</td>\n",
       "      <td>Taiwan(R.O.C)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(CCTV, ORG), (Nobel, WORK_OF_ART), (Mo Yan, P...</td>\n",
       "      <td>[invite, prize, Yan, literature, hint, CCTV, N...</td>\n",
       "      <td>[invite, prize, yan, literature, hint, cctv, n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  event_id            tweet_id  \\\n",
       "0        0  256292946331181056   \n",
       "1        0  256333064467279872   \n",
       "2        0  256334302034399232   \n",
       "3        0  256335853738160128   \n",
       "4        0  256346272506712064   \n",
       "\n",
       "                                                text    user_id  \\\n",
       "0  Nobel prize in literature to be announced http...   47667947   \n",
       "1  “@marvicleonen: Is it true that UP won UAAP ba...   67518107   \n",
       "2  Congrats, Ateneo! Last na yan ha. Season 76 wi...   97449266   \n",
       "3  \"@SMARTPromos: SMART never wants you to be lef...  405138197   \n",
       "4  CCTV invite hints at Nobel literature prize fo...  197326414   \n",
       "\n",
       "           created_at           user_loc place_type place_full_name  \\\n",
       "0 2012-10-11 07:19:34    Munich, Germany                              \n",
       "1 2012-10-11 09:58:59        Philippines                              \n",
       "2 2012-10-11 10:03:54                                                 \n",
       "3 2012-10-11 10:10:04  Lost in Dreamland                              \n",
       "4 2012-10-11 10:51:28      Taiwan(R.O.C)                              \n",
       "\n",
       "  place_country_code hashtags user_mentions image_urls  \\\n",
       "0                          []            []         []   \n",
       "1                          []    [28775032]         []   \n",
       "2                          []            []         []   \n",
       "3                          []   [106915372]         []   \n",
       "4                          []            []         []   \n",
       "\n",
       "                                            entities  \\\n",
       "0                                                 []   \n",
       "1     [(UP, ORG), (Next year, DATE), (Dean, PERSON)]   \n",
       "2            [(Ateneo, PERSON), (Season 76, PERSON)]   \n",
       "3                           [(BIG, ORG), (BIG, ORG)]   \n",
       "4  [(CCTV, ORG), (Nobel, WORK_OF_ART), (Mo Yan, P...   \n",
       "\n",
       "                                               words  \\\n",
       "0               [literature, Nobel, prize, announce]   \n",
       "1  [Dean, Sure, year, yan, na, \", basketball, tru...   \n",
       "2  [yan, ☺, na, ha, different, last, Ateneo, cong...   \n",
       "3  [never, s, yan, next, na, thing, Ano, leave, t...   \n",
       "4  [invite, prize, Yan, literature, hint, CCTV, N...   \n",
       "\n",
       "                                      filtered_words sampled_words        date  \n",
       "0               [literature, nobel, prize, announce]            []  2012-10-11  \n",
       "1  [dean, sure, year, yan, na, basketball, true, ...            []  2012-10-11  \n",
       "2  [yan, na, ha, different, last, ateneo, congrat...            []  2012-10-11  \n",
       "3  [never, yan, next, na, thing, ano, leave, that...            []  2012-10-11  \n",
       "4  [invite, prize, yan, literature, hint, cctv, n...            []  2012-10-11  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc6c99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a heterogeneous graph using tweet ids, user_ids, entities and rare(sampled) words(4 modalities模态)\n",
    "# if G is not None then insert new nodes to G\n",
    "# 创建heterogeneous graph\n",
    "def construct_graph_from_df(df, G=None):  # df: (11971, 18)\n",
    "    if G is None:\n",
    "        G = nx.Graph()  # 创建无向图\n",
    "    for _, row in df.iterrows():  # 返回可迭代元组(index,row)\n",
    "        # 1st modality: tweet_id\n",
    "        tid = 't_' + str(row['tweet_id'])\n",
    "        G.add_node(tid) # 一次添加一个节点，字符串作为节点id\n",
    "        G.nodes[tid]['tweet_id'] = True  # 设置节点属性；right-hand side value is irrelevant for the lookup\n",
    "        \n",
    "        # 2nd modality: user_id\n",
    "        user_ids = row['user_mentions']  # list.apend(str)\n",
    "        user_ids.append(row['user_id'])\n",
    "        user_ids = ['u_' + str(each) for each in user_ids]\n",
    "        G.add_nodes_from(user_ids) # 添加多个节点\n",
    "        for each in user_ids:\n",
    "            G.nodes[each]['user_id'] = True \n",
    "        \n",
    "        # 3rd modality: entities\n",
    "        entities = row['entities']  # 命名实体识别的实体\n",
    "#         words = ['e_' + each for each in entities]\n",
    "        G.add_nodes_from(entities)\n",
    "        for each in entities:\n",
    "            G.nodes[each]['entity'] = True\n",
    "        \n",
    "        # 4th modality:sampled_words\n",
    "        words = row['sampled_words']\n",
    "        words = ['w_' + each for each in words]\n",
    "        G.add_nodes_from(words)\n",
    "        for each in words:\n",
    "            G.nodes[each]['word'] = True\n",
    "        \n",
    "        edges =[]\n",
    "        edges += [(tid, each) for each in user_ids]\n",
    "        edges += [(tid, each) for each in entities]\n",
    "        edges += [(tid, each) for each in words]\n",
    "        G.add_edges_from(edges) # 同时添加多条边\n",
    "    return G  # 30427 nodes and 40238 edges,因为以tweet_id为主，加上user_id, entities, words共有30427个"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b15f26",
   "metadata": {},
   "source": [
    "### converting hete-graph to homo-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "767a10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a heterogeneous social graph G to a homogeneous message graph following eq. 1 of the paper, \n",
    "# and store the sparse binary adjacency matrix of the homogeneous message graph.\n",
    "# DGL(Deep Graph Library)构建更高效的图神经网络\n",
    "\n",
    "def dgl_hetegraph_to_homograph(G, save_path=None):\n",
    "    '''\n",
    "    doc_embeddings: (11971, 302)\n",
    "    df: (11971, 18)\n",
    "    30427 nodes and 40238 edges,因为以tweet_id为主，加上user_id, entities, words共有30427个\n",
    "    '''\n",
    "    message = ''\n",
    "    print('Start converting heterogeneous networks graph to homogeneous dgl graph.')\n",
    "    message += 'Start converting heterogeneous networks graph to homogeneous dgl graph.\\n'\n",
    "    all_start = time()\n",
    "    \n",
    "    print('\\tGetting a list of all nodes ...')\n",
    "    message += '\\tGetting a list of all nodes ...\\n'\n",
    "    start = time()\n",
    "    all_nodes = list(G.nodes)  # 30427个\n",
    "    mins = (time() - start) /60\n",
    "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\tGetting adjacency matrix ...')\n",
    "    message += '\\tGetting adjacency matrix ...\\n'\n",
    "    start = time()\n",
    "    A = nx.to_numpy_matrix(G) # Returns the graph adjacency matrix as a Numpy matrix, 整体异构图邻接矩阵，(30427, 30427)\n",
    "    mins = (time() - start)/ 60\n",
    "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # compute commuting matrices\n",
    "    print('\\tGetting lists of nodes of various types ...')\n",
    "    message += '\\tGetting lists of nodes of various types ...\\n'\n",
    "    start = time()\n",
    "    '''\n",
    "    all_nodes: 30427个\n",
    "    tweet_id: 11971\n",
    "    user_id: 11520\n",
    "    entity_id: 5401\n",
    "    word: 1535\n",
    "    '''\n",
    "    tid_nodes = list(nx.get_node_attributes(G, 'tweet_id').keys()) # get_node_attributes return node and its attributes;获得tweet_id列表\n",
    "    userid_nodes = list(nx.get_node_attributes(G, 'user_id').keys()) # 同理，获得user_id列表\n",
    "    word_nodes = list(nx.get_node_attributes(G, 'word').keys())\n",
    "    entity_nodes = list(nx.get_node_attributes(G, 'entity').keys())\n",
    "    del G  # 删除original 无向图\n",
    "    mins = (time() - start)/ 60\n",
    "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # 将节点转换成all_nodes中的索引index\n",
    "    print('\\tConverting node lists to index lists ...')\n",
    "    message += '\\tConverting node lists to index lists ...\\n'\n",
    "    start = time()\n",
    "    # fine细化 the index of target nodes in the list of all nodes\n",
    "    indices_tid = [all_nodes.index(x) for x in tid_nodes]        # 11971\n",
    "    indices_userid = [all_nodes.index(x) for x in userid_nodes]  # 11520\n",
    "    indices_word = [all_nodes.index(x) for x in word_nodes]      # 1535\n",
    "    indices_entity = [all_nodes.index(x) for x in entity_nodes]  # 5401\n",
    "    del tid_nodes\n",
    "    del userid_nodes\n",
    "    del word_nodes\n",
    "    del entity_nodes\n",
    "    mins = (time() -start)/60\n",
    "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # ----------------tweet-user-tweet------------------\n",
    "    print('\\tStart constructing tweet-user-tweet commuting matrix ...')\n",
    "    print('\\t\\t\\tStart constructing tweet-user matrix ...')\n",
    "    message += '\\tStart constructing tweet-user-tweet commuting matrix ...\\n\\t\\t\\tStart constructing tweet-user matrix ...\\n'\n",
    "    start = time()\n",
    "    # 笛卡尔积实际上是生成一个二维坐标矩阵，其作用是从A中抽取出x和y这两类节点的一个子邻接矩阵\n",
    "    w_tid_userid = A[np.ix_(indices_tid, indices_userid)]  # np.ix_(list1, list2)生成一个笛卡尔积的映射关系；\n",
    "    # return a N(indiced_tid)*N(indices_userid) matrix, representing the weight of edges between tid and userid\n",
    "    mins = (time() - start)/60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # convert to scipy sparse matrix\n",
    "    print('\\t\\t\\tConverting to sparse matrix ...')\n",
    "    message += '\\t\\t\\tConverting to sparse matrix ...\\n'\n",
    "    start = time()\n",
    "    s_w_tid_userid = sparse.csr_matrix(w_tid_userid) # 其实就是将邻接矩阵转换成稀疏矩阵。matrix compression\n",
    "    del w_tid_userid\n",
    "    mins = (time() - start)/ 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tTransposing ...')\n",
    "    message += '\\t\\t\\tTransposing ...\\n'\n",
    "    start = time()\n",
    "    s_w_userid_tid = s_w_tid_userid.transpose()  # 转置\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tCalculating tweet-user * user-tweet ...')\n",
    "    message += '\\t\\t\\tCalculating tweet-user * user-tweet ...\\n'\n",
    "    start = time()\n",
    "    '''\n",
    "    将meta-path: tweet-user-tweet转换成tweet-tweet矩阵，这样才能得到tweet_id0的直接邻居节点tweet_id1,2,3...，不用再隔着user关系。\n",
    "    '''\n",
    "    # csr_matrix, (11971, 11971)\n",
    "    s_m_tid_userid_tid = s_w_tid_userid * s_w_userid_tid #  根据user_id生成tweet_id homogeneous message graph\n",
    "    mins = (time() - start)/ 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tSaving ...')\n",
    "    message += '\\t\\t\\tSaving ...\\n'\n",
    "    start = time()\n",
    "    if save_path is not None:\n",
    "        sparse.save_npz(save_path + \"s_m_tid_userid_tid.npz\", s_m_tid_userid_tid)\n",
    "        print('sparse binary userid commuting matrix saved.')\n",
    "        del s_m_tid_userid_tid\n",
    "    del s_w_tid_userid\n",
    "    del s_w_userid_tid\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # ----------tweet-ent-tweet-----------------\n",
    "    print('\\tStart constructing tweet-ent-tweet conmuting matrix ...')\n",
    "    print('\\t\\t\\tStart constructing tweet-ent matrix ...')\n",
    "    message += '\\tStart constructing tweet-ent-tweet commuting matrix ...\\n\\t\\t\\tStart constructing tweet-ent matrix ...\\n'\n",
    "    start = time()\n",
    "    w_tid_entity = A[np.ix_(indices_tid, indices_entity)]  # 抽取tweet_id和entity的邻接矩阵\n",
    "    mins = (time() - start) / 60\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # convert to scipy sparse matrix\n",
    "    print('\\t\\t\\tConverting to sparse matrix ...')\n",
    "    message += '\\t\\t\\tConver ting to sparse matrix ...\\n'\n",
    "    start = time()\n",
    "    s_w_tid_entity = sparse.csr_matrix(w_tid_entity)  # 邻接矩阵转换成csr稀疏矩阵\n",
    "    del w_tid_entity\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed : ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tTransposing ...')\n",
    "    message += '\\t\\t\\tTransposing ...\\n'\n",
    "    start = time()\n",
    "    s_w_entity_tid = s_w_tid_entity.transpose()  # 转置\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tCalculating tweet-ent * ent-tweet ...')\n",
    "    message += '\\t\\t\\tCalculating tweet-ent * ent-tweet ...\\n'\n",
    "    start = time()\n",
    "    # csr_matrix, (11971, 11971)\n",
    "    s_m_tid_entity_tid = s_w_tid_entity * s_w_entity_tid  # 根据entity生成tweet_id homogeneous message graph\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tSaving ...')\n",
    "    message += '\\t\\t\\tSaving ...\\n'\n",
    "    start = time()\n",
    "    if save_path is not None:\n",
    "        sparse.save_npz(save_path + \"s_m_tid_entity_tid.npz\", s_m_tid_entity_tid)\n",
    "        print('Sparse binary entity commuting matrix saved.')\n",
    "        del s_m_tid_entity_tid\n",
    "    del s_w_tid_entity\n",
    "    del s_w_entity_tid\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # --------tweet-word-tweet------------------\n",
    "    print('\\tStart constructing tweet-word-tweet commuting matrix ...')\n",
    "    print('\\t\\t\\tStart constructing tweet-word matrix ...')\n",
    "    message +='\\tStart constructing tweet-wrod-tweet commuting matrix ...\\n\\t\\t\\tStart constructing tweet-word matrix ...'\n",
    "    start = time()\n",
    "    w_tid_word = A[np.ix_(indices_tid, indices_word)]\n",
    "    del A\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # convert to scipy sparse matrix\n",
    "    print('\\t\\t\\tConverting to Sparse matrix ...')\n",
    "    message += '\\t\\t\\tConverting to sparse matrix ...\\n'\n",
    "    start = time()\n",
    "    s_w_tid_word = sparse.csr_matrix(w_tid_word)  # tweet_id和word稀疏矩阵\n",
    "    del w_tid_word\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tTransposing ...')\n",
    "    message += '\\t\\t\\tTransposing ...\\n'\n",
    "    start = time()\n",
    "    s_w_word_tid = s_w_tid_word.transpose()\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tCalculating tweet-word * word-tweet ...')\n",
    "    message += '\\t\\t\\tCalculating tweet-word * word-tweet ...\\n'\n",
    "    start = time()\n",
    "    # csr_matrix, (11971, 11971)\n",
    "    s_m_tid_word_tid = s_w_tid_word * s_w_word_tid  # 根据word生成的tweet_id homogeneous message graph\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tSaving ...')\n",
    "    message += '\\t\\t\\tSaving ...\\n'\n",
    "    start = time()\n",
    "    if save_path is not None:\n",
    "        sparse.save_npz(save_path + \"s_m_tid_word_tid.npz\", s_m_tid_word_tid)\n",
    "        print(\"Sparse binary word commuting matrix saved.\")\n",
    "        del s_m_tid_word_tid\n",
    "    del s_w_tid_word\n",
    "    del s_w_word_tid\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # -----------compute tweet-tweet adjacency matrix --------\n",
    "    print('\\tComputing tweet-tweet adjacency matrix ...')\n",
    "    message += '\\tComputing tweet-tweet adjacency matrix ...\\n'\n",
    "    start = time()\n",
    "    if save_path is not None:\n",
    "        s_m_tid_userid_tid = sparse.load_npz(save_path + 's_m_tid_userid_tid.npz')\n",
    "        print(\"Sparse binary userid commuting matrix loaded.\")\n",
    "        s_m_tid_entity_tid = sparse.load_npz(save_path + \"s_m_tid_entity_tid.npz\")\n",
    "        print(\"Sparse binary entity commuting matrix loaded.\")\n",
    "        s_m_tid_word_tid = sparse.load_npz(save_path + \"s_m_tid_word_tid.npz\")\n",
    "        print(\"Sparse binary word commuting matrix loaded.\")\n",
    "    \n",
    "    # 合并三个user_id, entity, word生成的tweet_id homogeneous graph\n",
    "    s_A_tid_tid = s_m_tid_userid_tid + s_m_tid_entity_tid\n",
    "    del s_m_tid_userid_tid\n",
    "    del s_m_tid_entity_tid\n",
    "    # csr_matrix, (11971, 11971)\n",
    "    s_bool_A_tid_tid = (s_A_tid_tid + s_m_tid_word_tid).astype('bool')  # confirm the connect between tweets\n",
    "    del s_m_tid_word_tid\n",
    "    del s_A_tid_tid\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    all_mins = (time() - all_start) / 60\n",
    "    print('\\tOver all time elapsed: ', all_mins, ' mins\\n')\n",
    "    message += '\\tOver all time elapsed: '\n",
    "    message += str(all_mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    if save_path is not None:\n",
    "        sparse.save_npz(save_path + \"s_bool_A_tid_tid.npz\", s_bool_A_tid_tid)\n",
    "        print(\"Sparse binary adjacency matrix saved.\")\n",
    "        s_bool_A_tid_tid = sparse.load_npz(save_path + \"s_bool_A_tid_tid.npz\")\n",
    "        print(\"Sparse binary adjacency matrix loaded.\")\n",
    "        \n",
    "    # create correspoinding dgl graph\n",
    "    G = dgl.DGLGraph(s_bool_A_tid_tid)  # 传入稀疏矩阵，转换成图神经网络\n",
    "    print('We have %d nodes.' % G.number_of_nodes())\n",
    "    print('We have %d edges' % G.number_of_edges())\n",
    "    print()\n",
    "    message += 'We have '\n",
    "    message += str(G.number_of_nodes())\n",
    "    message += ' nodes.'\n",
    "    message += 'We have '\n",
    "    message += str(G.number_of_edges())\n",
    "    message += ' edges.\\n'\n",
    "    \n",
    "    return all_mins, message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2ae39",
   "metadata": {},
   "source": [
    "### construct offline dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20157f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c9e8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To switch to the All Message Strategy or the Relevant Message Strategy, replace 'G = construct_graph_from_df(incr_df)' with 'G = construct_graph_from_df(incr_df, G)'.\n",
    "# 2) For test purpose, set test=True, and the message blocks, as well as the resulted message graphs each will contain 100 messages.\n",
    "# To use all the messages, set test=False, and the number of messages in the message blocks will follow Table. 4 of the paper.\n",
    "def construct_offline_dataset(df, save_path, features_embeddings, test=True):\n",
    "    '''\n",
    "    df: (11971, 18)\n",
    "    feature_embeddings: (68841, 302)\n",
    "    '''\n",
    "    # If test equals true, construct the initial graph using test_ini_size_tweets\n",
    "    # and increment the graph by test_incr_size tweets each day\n",
    "    test_ini_size = 500\n",
    "    test_incr_size = 100\n",
    "    \n",
    "    # save data splits for training/validate/test mask generation\n",
    "    data_split = []\n",
    "    # save time spent for the heterogeneous -> homogeneous conversion of each graph\n",
    "    all_graph_mins = []\n",
    "    message = ''\n",
    "    # extract distingct dates\n",
    "    distinct_dates = df.date.unique() # 所有unique的date\n",
    "    print('Number of distinct dates: ', len(distinct_dates))\n",
    "    message += 'Number of distinct dates: '\n",
    "    message += str(len(distinct_dates))\n",
    "    message += '\\n'\n",
    "    \n",
    "    # split data by dates and construct graphs\n",
    "    # first week -> initial graph (20254 tweets)\n",
    "    print('Start constructing initial graph ...')\n",
    "    message += '\\nStart constructing initial graph ...\\n'\n",
    "#     ini_df = df.loc[df['date'].isin(distinct_dates[:7])]  # find top 7 days\n",
    "#     if test:\n",
    "#         ini_df = ini_df[: test_ini_size]  # top test_ini_size dates\n",
    "    G = construct_graph_from_df(df)  # graph with 30427 nodes and 40238 edges\n",
    "    path = save_path\n",
    "    if path is None:\n",
    "        os.mkdir(path)  # 创建目录\n",
    "    graph_mins, graph_message = dgl_hetegraph_to_homograph(G, save_path=path)  # convert a heterogeneous social graph to a homogeneous message graph\n",
    "    message += graph_message\n",
    "    print('Initial graph saved')\n",
    "    message += 'Initial graph saved\\n'\n",
    "    # record the totoal number of tweets\n",
    "    all_graph_mins.append(graph_mins)\n",
    "    # extract and save the labels of corresponding tweets\n",
    "    labels = [int(each) for each in df['event_id'].values]  # 11971\n",
    "    np.save(path + 'labels.npy', np.asarray(labels))  # ndarray对象，实际只创建一个指针\n",
    "    print('Labels saved.')\n",
    "    message += 'Labels saved.\\n'\n",
    "    # extract and save the features of corresponding tweets\n",
    "    indices = df['index'].values.tolist()  # 11971\n",
    "    x = features_embeddings[indices, :]  # (11971, 302), features是指combined_features: document_embeddings + time_features\n",
    "    np.save(path + 'features_embeddings.npy', x)\n",
    "    print('Features saved.')\n",
    "    message += 'Features saved. \\n\\n'\n",
    "    \n",
    "#     # subsequent days -> insert tweets day by day(skip the last day because it only contains on tweet)\n",
    "#     for i in range(7, len(distinct_dates) -1):\n",
    "#         print('Start constructing graph', str(i - 6), '...')\n",
    "#         message += '\\nStart constructing graph'\n",
    "#         message += str(i-6)\n",
    "#         message += '...\\n'\n",
    "#         incr_df = df.loc[df['date']==distinct_dates[i]]\n",
    "#         if test:\n",
    "            \n",
    "    return message, all_graph_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "590f8dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 68838, 68839, 68840], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35e483",
   "metadata": {},
   "source": [
    "### run-offline dataset: 4days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7dab4bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51113bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n",
      "Data converted to dataframe.\n",
      "Number of distinct dates:  4\n",
      "Start constructing initial graph ...\n",
      "Start converting heterogeneous networks graph to homogeneous dgl graph.\n",
      "\tGetting a list of all nodes ...\n",
      "\tDone. Time elapsed:  1.6542275746663413e-05  mins\n",
      "\n",
      "\tGetting adjacency matrix ...\n",
      "\tDone. Time elapsed:  0.07835565805435181  mins\n",
      "\n",
      "\tGetting lists of nodes of various types ...\n",
      "\tDone. Time elapsed:  0.0017293771107991537  mins\n",
      "\n",
      "\tConverting node lists to index lists ...\n",
      "\tDone. Time elapsed:  0.41532753308614095  mins\n",
      "\n",
      "\tStart constructing tweet-user-tweet commuting matrix ...\n",
      "\t\t\tStart constructing tweet-user matrix ...\n",
      "\t\t\tDone. Time elapsed:  0.018926910559336343  mins\n",
      "\n",
      "\t\t\tConverting to sparse matrix ...\n",
      "\t\t\tDone. Time elapsed:  0.021055559317270916  mins\n",
      "\n",
      "\t\t\tTransposing ...\n",
      "\t\t\tDone. Time elapsed:  0.0  mins\n",
      "\n",
      "\t\t\tCalculating tweet-user * user-tweet ...\n",
      "\t\t\tDone. Time elapsed:  1.6756852467854817e-05  mins\n",
      "\n",
      "\t\t\tSaving ...\n",
      "sparse binary userid commuting matrix saved.\n",
      "\t\t\tDone. Time elapsed:  0.0003055055936177572  mins\n",
      "\n",
      "\tStart constructing tweet-ent-tweet conmuting matrix ...\n",
      "\t\t\tStart constructing tweet-ent matrix ...\n",
      "\t\t\tConverting to sparse matrix ...\n",
      "\t\t\tDone. Time elapsed :  0.0  mins\n",
      "\n",
      "\t\t\tTransposing ...\n",
      "\t\t\tDone. Time elapsed:  0.0  mins\n",
      "\n",
      "\t\t\tCalculating tweet-ent * ent-tweet ...\n",
      "\t\t\tDone. Time elapsed:  0.0  mins\n",
      "\n",
      "\t\t\tSaving ...\n",
      "Sparse binary entity commuting matrix saved.\n",
      "\t\t\tDone. Time elapsed:  1.6585985819498697e-05  mins\n",
      "\n",
      "\tStart constructing tweet-word-tweet commuting matrix ...\n",
      "\t\t\tStart constructing tweet-word matrix ...\n",
      "\t\t\tDone. Time elapsed:  0.020923487345377603  mins\n",
      "\n",
      "\t\t\tConverting to Sparse matrix ...\n",
      "\t\t\tDone. Time elapsed:  0.0028400818506876626  mins\n",
      "\n",
      "\t\t\tTransposing ...\n",
      "\t\t\tDone. Time elapsed:  0.0  mins\n",
      "\n",
      "\t\t\tCalculating tweet-word * word-tweet ...\n",
      "\t\t\tDone. Time elapsed:  3.3235549926757814e-05  mins\n",
      "\n",
      "\t\t\tSaving ...\n",
      "Sparse binary word commuting matrix saved.\n",
      "\t\t\tDone. Time elapsed:  0.0002493580182393392  mins\n",
      "\n",
      "\tComputing tweet-tweet adjacency matrix ...\n",
      "Sparse binary userid commuting matrix loaded.\n",
      "Sparse binary entity commuting matrix loaded.\n",
      "Sparse binary word commuting matrix loaded.\n",
      "\t\t\tDone. Time elapsed:  0.0009699900945027669  mins\n",
      "\n",
      "\tOver all time elapsed:  0.5608330845832825  mins\n",
      "\n",
      "Sparse binary adjacency matrix saved.\n",
      "Sparse binary adjacency matrix loaded.\n",
      "We have 11971 nodes.\n",
      "We have 167017 edges\n",
      "\n",
      "Initial graph saved\n",
      "Labels saved.\n",
      "Features saved.\n",
      "Time spent on heterogeneous -> homogeneous graph conversions:  [0.5608330845832825]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "offline_save_path = project_path + '/result/FinEvent result/offline dataset/'\n",
    "if not os.path.exists(offline_save_path):\n",
    "    os.mkdir(offline_save_path)\n",
    "\n",
    "# load data (68841 tweets, multiclasses filtered)\n",
    "p_part1 = load_path + '68841_tweets_multiclasses_filtered_0722_part1.npy'\n",
    "p_part2 = load_path + '68841_tweets_multiclasses_filtered_0722_part2.npy'\n",
    "# allow_pickle: 可选，布尔值，允许使用 Python pickles 保存对象数组，Python 中的 pickle 用于在保存到磁盘文件或从磁盘文件读取之前，对对象进行序列化和反序列化。\n",
    "df_np_part1 = np.load(p_part1, allow_pickle=True)  \n",
    "df_np_part2 = np.load(p_part2, allow_pickle=True)\n",
    "df_np = np.concatenate((df_np_part1, df_np_part2), axis=0)  # (68840, 16)\n",
    "print('Data loaded.')\n",
    "df = pd.DataFrame(data=df_np, columns=['event_id', 'tweet_id', 'text', 'user_id', 'created_at', 'user_loc',\n",
    "                                      'place_type', 'place_full_name', 'place_country_code', 'hashtags',\n",
    "                                      'user_mentions', 'image_urls', 'entities', 'words', 'filtered_words', 'sampled_words'])\n",
    "print('Data converted to dataframe.')\n",
    "\n",
    "# sort date by time\n",
    "df = df.sort_values(by='created_at').reset_index(drop=True)\n",
    "# append date\n",
    "df['date'] = [d.date() for d in df['created_at']]\n",
    "# 因为graph太大，爆了内存，所以取4天的twitter data做demo，后面用nci server\n",
    "init_day = df.loc[0, 'date']\n",
    "df = df[(df['date']>= init_day) & (df['date']<= init_day + datetime.timedelta(days=3))].reset_index()  # (11971, 18)\n",
    "# load features\n",
    "# the dimension of combined_feature is 302 in this dataset: document_features-300 + time_features-2\n",
    "f = np.load(project_path + '/result/FinEvent result/combined_features.npy')  # (11971, 302)\n",
    "\n",
    "# generate test graphs, features, and labels\n",
    "message, all_graph_mins = construct_offline_dataset(df, offline_save_path, f, True)\n",
    "with open(offline_save_path + 'node_edge_statistics.txt', 'w') as text_file:\n",
    "    text_file.write(message)\n",
    "np.save(offline_save_path + 'all_graph_min.npy', np.asarray(all_graph_mins))\n",
    "print('Time spent on heterogeneous -> homogeneous graph conversions: ', all_graph_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1460ff81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c52d3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.date(2012, 10, 10), datetime.date(2012, 10, 11),\n",
       "       datetime.date(2012, 10, 12), datetime.date(2012, 10, 13)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a99adad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82dadfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11971, 18)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c3d15",
   "metadata": {},
   "source": [
    "#### data_split: 4 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb18b893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "986d33dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# data_split保存的是message_block的数据量。e.g. data_split = [  500  ,   100, ...,  100]\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#                                                         block_0  block_1    block_n\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# demo: data_split\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m dividing_point \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m      6\u001b[0m data_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      8\u001b[0m data_split \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# data_split保存的是message_block的数据量。e.g. data_split = [  500  ,   100, ...,  100]\n",
    "#                                                         block_0  block_1    block_n\n",
    "# demo: data_split\n",
    "import math\n",
    "dividing_point = int(df.shape[0] / 6)\n",
    "data_amount = 0\n",
    "\n",
    "data_split = []\n",
    "for i in range(5):\n",
    "    data_amount += dividing_point\n",
    "    if i < 2:\n",
    "        continue\n",
    "    else:\n",
    "        data_split.append(data_amount)\n",
    "data_split.append(df.shape[0])\n",
    "# save data_split.npy\n",
    "np.save(save_path + '/offline dataset/data_split.npy', np.array(data_split))\n",
    "# save edge_index_[entity, userid, word].pt 文件\n",
    "data_path_temp = project_path + '/result/FinEvent result/offline dataset/'\n",
    "relations = ['entity', 'userid', 'word']\n",
    "for relation in relations:\n",
    "    relation_edge_index = sparse_trans(os.path.join(data_path_temp, 's_m_tid_%s_tid.npz' % relation))\n",
    "    torch.save(relation_edge_index, data_path_temp + '/edge_index_%s.pt' % relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b2388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05442cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2289c536",
   "metadata": {},
   "source": [
    "### run-incremental dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5ab1a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_multi_relational_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m22\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m----> 8\u001b[0m     \u001b[43msave_multi_relational_graph\u001b[49m(data_path, relation_ids, [\u001b[38;5;241m0\u001b[39m,i])\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge index saved\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall edge index saved\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'save_multi_relational_graph' is not defined"
     ]
    }
   ],
   "source": [
    "# acclerate the training process\n",
    "import torch\n",
    "\n",
    "data_path = save_path\n",
    "relation_ids = ['entity', 'userid', 'word']\n",
    "for i in range(22):\n",
    "    print(i)\n",
    "    save_multi_relational_graph(data_path, relation_ids, [0,i])\n",
    "    print('edge index saved')\n",
    "print('all edge index saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd09919",
   "metadata": {},
   "source": [
    "# FinEvent Model Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9cb4fa",
   "metadata": {},
   "source": [
    "## Fundemental models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6265ad59",
   "metadata": {},
   "source": [
    "### GAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61021ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.functional import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv  # PyG封装好的GATConv函数\n",
    "from torch.nn import Linear, BatchNorm1d, Sequential, ModuleList, ReLU, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c066594",
   "metadata": {},
   "source": [
    "#### GAT model for mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f1a8a7e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    '''\n",
    "    adopt this module when using mini-batch\n",
    "    '''\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, heads) -> None:\n",
    "        super(GAT, self).__init__()\n",
    "        self.GAT1 = GATConv(in_channels=in_dim, out_channels=hid_dim, heads=heads, add_self_loops=False)  # 输入节点的特征维度，隐藏层节点的维度\n",
    "        self.GAT2 = GATConv(in_channels=hid_dim*heads, out_channels=out_dim, add_self_loops=False)  # 隐藏层维度，输出维度\n",
    "        self.layers = ModuleList([self.GAT1, self.GAT2])\n",
    "        self.norm = BatchNorm1d(heads * hid_dim)  # 将num_features那一维进行归一化，防止梯度扩散\n",
    "    \n",
    "    def forward(self, x, adjs, device):\n",
    "        for i, (edge_index, _, size) in enumerate(adjs): # 返回一个可遍历对象，同时列出数据和数据下标\n",
    "            # x: Tensor, edge_index: Tensor\n",
    "            x, edge_index = x.to(device), edge_index.to(device)\n",
    "            x_target = x[:size[1]]  # Target nodes are always placed first\n",
    "            x = self.layers[i]((x,x_target), edge_index)\n",
    "            if i == 0:\n",
    "                x = self.norm(x)  # 归一化操作，防止梯度散射\n",
    "                x = F.elu(x)  # 非线性激活函数elu\n",
    "                x = F.dropout(x, training=self.training)\n",
    "            del edge_index\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd62de1",
   "metadata": {},
   "source": [
    "#### Intra_AGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba7f1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT model\n",
    "class Intra_AGG(nn.Module):  # intra-aggregation\n",
    "    def __init__(self, GAT_args):\n",
    "        super(Intra_AGG, self).__init__()\n",
    "        in_dim, hid_dim, out_dim, heads = GAT_args\n",
    "        self.gnn = GAT(in_dim, hid_dim, out_dim, heads)\n",
    "    \n",
    "    def forward(self, x, adjs, device):\n",
    "        x = self.gnn(x, adjs, device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96abb144",
   "metadata": {},
   "source": [
    "#### Inter_AGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0328ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp model\n",
    "class Inter_AGG(nn.Module):  # inter-aggregation\n",
    "    def __init__(self, mlp_args=None):\n",
    "        super(Inter_AGG, self).__init__()\n",
    "        if mlp_args is not None:\n",
    "            hid_dim, out_dim = mlp_args\n",
    "            self.mlp = nn.Sequential(\n",
    "                        Linear(hid_dim, hid_dim),\n",
    "                        BatchNorm1d(hid_dim),\n",
    "                        ReLU(inplace=True),\n",
    "                        Dropout(),\n",
    "                        Linear(hid_dim, out_dim),\n",
    "                        )\n",
    "    def forward(self, features, thresholds, inter_opt):\n",
    "        batch_size = features[0].size(0)\n",
    "        features = torch.transpose(features, dim0=0, dim1=1)\n",
    "        if inter_opt == 'cat_wo_avg':\n",
    "            features = features.reshape(batch_size, -1)\n",
    "        elif inter_opt == 'cat_w_avg':\n",
    "            # weighted average and concatenate\n",
    "            features = torch.mul(features, thresholds).reshape(batch_size, -1)\n",
    "        elif inter_opt == 'cat_w_avg_mlp':\n",
    "            features = torch.mul(features, thresholds).reshape(batch_size, -1)\n",
    "            features = self.mlp(features)\n",
    "        elif inter_opt == 'cat_wo_avg_mlp':\n",
    "            features = torch.mul(features, thresholds).reshape(batch_size, -1)\n",
    "            features = self.mlp(features)\n",
    "        elif inter_opt == 'add_wo_avg':\n",
    "            features = features.sum(dim=1)\n",
    "        elif inter_opt == 'add_w_avg':\n",
    "            features = torch.mul(features, thresholds).sum(dim=1)\n",
    "        return features\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d44c28",
   "metadata": {},
   "source": [
    "### TripletLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee84cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3cf771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies an average on seq, of shape(nodes, features)\n",
    "class AvgReadout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AvgReadout, self).__init__()\n",
    "    def forward(self, seq):\n",
    "        return torch.mean(seq, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2dd4e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):  # 鉴别器\n",
    "    def __init__(self, n_h):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.f_k = nn.Bilinear(n_h, n_h, 1)  # 双向现行变换x1*A*x2\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "    \n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, m.Bilinear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)  # 权值初始化方法，均分分布\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "    \n",
    "    def forward(self, c, h_pl, h_mi, s_bias1=None, s_bias2=None):\n",
    "        c_x = torch.unsqueeze(c, 0)\n",
    "        c_x = c_x.expand_as(h_pl)  # torch.randn(size*)生成size维数组；expand是扩展到size_new数组；expand_as是扩展到像y的数组\n",
    "        sc_1 = torch.squeeze(self.f_k(h_pl, c_x), 1)\n",
    "        sc_2 = torch.squeeze(self.f_k(h_mi, c_x), 1)\n",
    "        if s_bias1 is not None:\n",
    "            sc_1 += s_bias1\n",
    "        if s_bias2 is not None:\n",
    "            sc_2 += s_bias2\n",
    "        logits = torch.cat((sc_1, sc_2), 0)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dee20b",
   "metadata": {},
   "source": [
    "#### triplet_loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12d86760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算triplet_loss损失函数\n",
    "class OnlineTripletLoss(nn.Module):\n",
    "    '''\n",
    "    Online Triplets loss\n",
    "    Takes a batch of embeddings and corresponding labels\n",
    "    Triplets are generated using triplet_selector objects that take embeddings and targets and return indices of triplets\n",
    "    '''\n",
    "    def __init__(self, margin, triplet_selector):\n",
    "        super(OnlineTripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.triplet_selector = triplet_selector  # selector选择器对象，含有get_triplets方法\n",
    "    \n",
    "    def forward(self, embeddings, target):\n",
    "        triplets = self.triplet_selector.get_triplets(embeddings, target)  # 根据embeddings和labels返回最大loss index list\n",
    "        # if embeddings.is_cuda():\n",
    "        #     triplets = triplets.cuda()\n",
    "        # embeddings矩阵索引是单个元素，取行向量，多个行向量又组成矩阵！！\n",
    "        ap_distances = (embeddings[triplets[:,0]] - embeddings[triplets[:,1]]).pow(2).sum(1) # .pow(.5); \n",
    "        an_distances = (embeddings[triplets[:,0]] - embeddings[triplets[:,2]]).pow(2).sum(1) # .pow(.5)\n",
    "        losses = F.relu(ap_distances - an_distances + self.margin)\n",
    "        \n",
    "        return losses.mean(), len(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c98105e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f03e8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletSelector:\n",
    "    '''\n",
    "    Implementation should return indices of anchors, positive and negative samples\n",
    "    return np array of shape [N_triplets * 3]\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def get_triplets(self, embeddings, labels):\n",
    "        raise NotImplementedError  # 如果这个方法没有被子类重写，但是调用了，就会报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48daa5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_demo = [1,0,0,1,2,3]\n",
    "for label in set(labels_demo):\n",
    "    label_mask_demo = (labels_demo == label)\n",
    "    label_indices_demo = np.where(label_mask_demo)[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b2526c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_indices_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f39c267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mask_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46f63f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_positives = np.array([(0, 2), (0, 3), (2, 3)])\n",
    "anchor_positives[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ba2ef9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0,2])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f288c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_demo = torch.randn(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9bd66898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6280,  2.0057, -0.6209,  0.0762],\n",
       "        [ 0.6341,  1.5761, -0.1927,  0.7800],\n",
       "        [ 2.2200, -0.5745,  1.6787, -1.3785],\n",
       "        [-1.6311, -1.0245,  0.4135,  1.5535]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dee99cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2200, -0.5745,  1.6787, -1.3785],\n",
       "        [ 0.6341,  1.5761, -0.1927,  0.7800],\n",
       "        [-1.6311, -1.0245,  0.4135,  1.5535]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_demo[np.array([2,1,3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab874ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 矩阵计算\n",
    "def distance_matrix_computation(vectors):\n",
    "    distance_matrix=-2*vectors.mm(torch.t(vectors))+vectors.pow(2).sum(dim=1).view(1,-1)+vectors.pow(2).sum(dim=1).view(-1,1)\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1efdf8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_demo = torch.tensor([2,1,2,3]).data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6d119",
   "metadata": {},
   "source": [
    "#### triplet_loss_max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4fed9b07",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 具体实现三元损失函数triplets_loss，返回某标签下ith元素和jth元素，其最大loss对应的其他标签元素索引\n",
    "\n",
    "class FunctionNegativeTripletSelector(TripletSelector):\n",
    "    '''\n",
    "    For each positive pair, takes the hardes negative sample (with the greatest triplet loss value) to create a triplet\n",
    "    Margin should match the margin userd in triplet loss.\n",
    "    negative_selection_fn should take array of loss_values for a given anchor-positive pair and all negative samples\n",
    "    and return a negative index for that pair\n",
    "    '''\n",
    "    def __init__(self, margin, negative_selection_fn, cpu=True):\n",
    "        super(FunctionNegativeTripletSelector, self).__init__()\n",
    "        self.cpu = cpu\n",
    "        self.margin = margin\n",
    "        self.negative_selection_fn = negative_selection_fn  # 返回loss_values最大元素值的index的selector\n",
    "    \n",
    "    def get_triplets(self, embeddings, labels):\n",
    "        if self.cpu:\n",
    "            embeddings = embeddings.cpu()\n",
    "        distance_matrix = distance_matrix_computation(embeddings)  # 计算distance matrix\n",
    "        distance_matrix = distance_matrix.cpu()  \n",
    "        \n",
    "        labels = labels.cpu().data.numpy()\n",
    "        triplets = []\n",
    "        \n",
    "        # embedding计算的distance matrix与labels计算loss，取最大loss_index\n",
    "        # 对于每个标签label\n",
    "        for label in set(labels):\n",
    "            label_mask = (labels == label)  # numpy array([True, False, True, True])\n",
    "            label_indices = np.where(label_mask)[0]  # 标签索引, label_index, array([0, 2, 3], dtype=int64)\n",
    "            if len(label_indices) < 2:\n",
    "                continue\n",
    "            negative_indices = np.where(np.logical_not(label_mask))[0]  # 其他标签索引, not_label_index, array([1], dtype=int64)\n",
    "            anchor_pos_list = list(combinations(label_indices, 2)) # 2个元素的标签索引组合, [(0, 2), (0, 3), (2, 3)]\n",
    "            anchor_pos_list = np.array(anchor_pos_list)  # 转换成np.array才能进行slice切片操作\n",
    "            \n",
    "            # 按照anchor_positive index从距离矩阵中抽取distance；0-index，array([0, 0, 2]);\n",
    "            # 提取标签label的i-element与j-element距离。\n",
    "            anchor_p_distances = distance_matrix[anchor_pos_list[:,0], anchor_pos_list[:,1]] #类似组成坐标，tensor([-1.1761,-0.8381,0.0099])\n",
    "            for anchor_positive, ap_distance in zip(anchor_pos_list, anchor_p_distances): # 每个标签下，元素组合、元素距离\n",
    "                # 0表示ith元素到各个其他标签元素的距离。\n",
    "                # 同一标签下(ith,jth)距离 - ith元素到其他标签元素的距离 + self.margin边际收益\n",
    "                loss_values = ap_distance - distance_matrix[  \n",
    "                    torch.LongTensor(np.array([anchor_positive[0]])), torch.LongTensor(negative_indices)] + self.margin\n",
    "                loss_values = loss_values.data.cpu().numpy()\n",
    "                hard_neg_max_index = self.negative_selection_fn(loss_values)  # hard返回最大loss的索引\n",
    "                if hard_neg_max_index is not None:  # if 最大loss值非空，则返回其他标签元素的索引\n",
    "                    hard_negative = negative_indices[hard_neg_max_index] \n",
    "                    # 对于谋标签下ith元素和jth元素，其最大loss对应的其他标签元素索引\n",
    "                    triplets.append([anchor_positive[0], anchor_positive[1], hard_negative]) \n",
    "        \n",
    "        if len(triplets) == 0:\n",
    "            triplets.append([anchor_positive[0], anchor_positive[1], negative_indices[0]])\n",
    "        \n",
    "        triplets = np.array(triplets)\n",
    "        return torch.LongTensor(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3672739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机-loss随机负值\n",
    "def random_hard_negative(loss_values):\n",
    "    hard_negatives = np.where(loss_values > 0)[0]\n",
    "    return np.random.choice(hard_negatives) if len(hard_negatives) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f967984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 硬-loss最大负值\n",
    "def hardest_negative(loss_values):\n",
    "    hard_negative = np.argmax(loss_values)\n",
    "    return hard_negative if loss_values[hard_negative] > 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef5942",
   "metadata": {},
   "source": [
    "#### hard_tri-loss_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3db1ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 硬三元损失函数\n",
    "def HardestNegativeTripletSelector(margin, cpu=False):\n",
    "    return FunctionNegativeTripletSelector(margin=margin, negative_selection_fn=hardest_negative, cpu=cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bce64d2",
   "metadata": {},
   "source": [
    "#### random_tri-loss_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d19d6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机三元损失函数\n",
    "def RandomNegativeTripletSelector(margin, cpu=False):\n",
    "    return FunctionNegativeTripletSelector(margin=margin, negative_selection_fn=random_hard_negative, cpu=cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fef0a5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6396]],\n",
       "\n",
       "        [[-1.4468]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e90faf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5154,  0.0506,  0.3423],\n",
       "         [ 0.8576, -0.1571,  1.4457],\n",
       "         [-0.6813, -1.2860, -1.3743]],\n",
       "\n",
       "        [[-0.1772, -0.4001, -0.8635],\n",
       "         [-1.0015, -2.0096,  0.1044],\n",
       "         [-1.8040,  0.8419,  0.6068]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024f7ef",
   "metadata": {},
   "source": [
    "### NeighborRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0935aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.functional import Tensor\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6203a30",
   "metadata": {},
   "source": [
    "#### cal_similarity_node_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c344fe5",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cal_similarity_node_edge(multi_r_data, features, save_path=None):\n",
    "    '''\n",
    "    This is used to culculate the similarity between node and its neighbors in advance \n",
    "    in order to avoid the repetitive computation.\n",
    "    Args:\n",
    "        multi_r_data ([type]): [description]\n",
    "        features ([type]): [description]\n",
    "        save_path ([type], optional): [description]. Defaults to None.\n",
    "    '''\n",
    "    relation_config: Dict[str, Dict[int, Any]] = {}\n",
    "    for relation_id, r_data in enumerate(multi_r_data):\n",
    "        node_config: Dict[int, Any] = {}\n",
    "        r_data: Tensor\n",
    "        unique_nodes = r_data[1].unique()\n",
    "        num_nodes = unique_nodes.size(0)\n",
    "        for node in range(num_nodes):\n",
    "            # get neighbors' index\n",
    "            neighbors_idx = torch.where(r_data[1]==node)[0]\n",
    "            # get neghbors\n",
    "            neighbors = r_data[0, neighbors_idx]\n",
    "            num_neighbors = neighbors.size(0)\n",
    "            neighbors_features = features[neighbors, :]\n",
    "            target_features = features[node, :]\n",
    "            # calculate enclidean distance with broadcast\n",
    "            dist: Tensor = torch.norm(neighbors_features - target_features, p=2, dim=1)  # torch.norm求a列维度(dim指定)的2(p指定)范数(长度)\n",
    "            # smaller is better and we use 'top p' in our paper\n",
    "            # (threshold * num_neighbors) see RL_neighbor_filter for details\n",
    "            sorted_neighbors, sorted_index = dist.sort(descending=False)\n",
    "            node_config[node] = {'neighbors_idx': neighbors_idx,\n",
    "                                'sorted_neighbors': sorted_neighbors,\n",
    "                                'sorted_index': sorted_index,\n",
    "                                'num_neighbors': num_neighbors}\n",
    "        relation_config['relation_%d' % relation_id] = node_config\n",
    "    if save_path is not None:\n",
    "        print(save_path)\n",
    "        save_path = os.path.join(save_path, 'relation_config.npy')\n",
    "        np.save(save_path, relation_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db06b89",
   "metadata": {},
   "source": [
    "#### RL_neighbor_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71a8616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回filtered neighbor index\n",
    "def RL_neighbor_filter(multi_r_data, RL_thtesholds, load_path):\n",
    "    load_path = os.path.join(load_path, 'relation_config.npy')\n",
    "    relation_config = np.load(load_path, allow_pickle=True)\n",
    "    relation_config = relation_config.tolist()\n",
    "    relations = list(relation_config.keys())\n",
    "    multi_remain_data = []\n",
    "    \n",
    "    for i in range(len(relations)):\n",
    "        edge_index: Tensor = multi_r_data[i]\n",
    "        unique_nodes = edge_index[1].unique()\n",
    "        num_nodes = unique_nodes.size(0)\n",
    "        remain_node_index = torch.tensor([])\n",
    "        for node in range(num_nodes):\n",
    "            # extract config\n",
    "            neighbors_idx = relation_config[relations[i]][node]['neighbors_idx']\n",
    "            num_neighbors = relation_config[relations[i]][node]['num_neighbors']\n",
    "            sorted_neighbors = relation_config[relations[i]][node]['sorted_neighbors']\n",
    "            sorted_index = relation_config[relations[i]][node]['sorted_index']\n",
    "            \n",
    "            if num_neighbors < 5:\n",
    "                remain_node_index = torch.cat((remain_node_index, neighbors_idx))\n",
    "                continue  # add limitations\n",
    "            \n",
    "            threshold = float(RL_thtesholds[i])\n",
    "            \n",
    "            num_kept_neighbors = math.ceil(num_neighbors * threshold) + 1\n",
    "            num_kept_neighbors_idx = neighbors_idx[sorted_index[:num_kept_neighbors]]\n",
    "            filtered_neighbors_idx = neighbors_idx[sorted_index[:num_kept_neighbors]]\n",
    "            remain_node_index = torch.cat((remain_node_index, filtered_neighbors_idx))\n",
    "            \n",
    "        remain_node_index = remain_node_index.type('torch.LongTensor')\n",
    "        edge_index = edge_index[:, remain_node_index]\n",
    "        multi_remain_data.append(edge_index)\n",
    "    \n",
    "    return multi_remain_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d0558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa8ada47",
   "metadata": {},
   "source": [
    "# FinEvent Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071df23",
   "metadata": {},
   "source": [
    "## gen_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7f3789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.coo import coo_matrix\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from scipy import sparse\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_sparse.tensor import SparseTensor\n",
    "# from .utils import generateMasks, gen_offline_masks，是指从utils.py文件中导入函数: generatemasks, gen_offline_masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1de4b8c",
   "metadata": {},
   "source": [
    "### sparse_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5fd5d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relations_ids = ['entity', 'userid', 'word'],分别读取这三个文件\n",
    "def sparse_trans(datapath = 'incremental_0808/0/s_m_tid_userid_tid.npz'):\n",
    "    relation = sparse.load_npz(datapath)  # (11971, 11971)\n",
    "    all_edge_index = torch.tensor([], dtype=int)\n",
    "    for node in range(relation.shape[0]):\n",
    "        neighbor = torch.IntTensor(relation[node].toarray()).squeeze()  # IntTensor是torch定义的7中cpu tensor类型之一；\n",
    "                                                                        # squeeze对数据维度进行压缩，删除所有为1的维度\n",
    "        # del self_loop in advance\n",
    "        neighbor[node] = 0\n",
    "        neighbor_idx = neighbor.nonzero()  # 返回非零元素的索引\n",
    "        neighbor_sum = neighbor_idx.size(0)  # 表示第0维度的数据量\n",
    "        loop = torch.tensor(node).repeat(neighbor_sum, 1)  # repeat表示沿着指定的维度重复tensor的次数\n",
    "        edge_index_i_j = torch.cat((loop, neighbor_idx), dim=1).t()  # cat表示拼接；t表示对二维矩阵进行转置\n",
    "        self_loop = torch.tensor([[node], [node]])\n",
    "        all_edge_index = torch.cat((all_edge_index, edge_index_i_j, self_loop), dim=1)\n",
    "        del neighbor, neighbor_idx, loop, self_loop, edge_index_i_j\n",
    "    return all_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8145cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coo_trans(datapath = 'incremental_0808/0/s_m_tid_userid_tid.npz'):\n",
    "    relation: csr_matrix = sparse.load_npz(datapath)\n",
    "    relation: coo_matrix = relation.tocoo()\n",
    "    sparse_edge_index = torch.LongTensor([relation.row, relation.col])  # sparse稀疏矩阵用三元组(row,col,data)来存储非零元素信息\n",
    "    return sparse_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d56ffbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(loadpath, relation, mode):\n",
    "    features = np.load(os.path.join(loadpath, str(mode[1]), 'features_embeddings.npy'))\n",
    "    features = torch.FloatTensor(features)\n",
    "    print('features laoded')\n",
    "    labels = np.load(os.path.join(loadpath, str(mode[1]), 'labels.npy'))\n",
    "    print('labels loaded')\n",
    "    labels = torch.LongTensor(labels)\n",
    "    relation_edge_index = coo_trans(os.path.join(loadpath, str(mode[1]), 's_m_tid_%s_tid.npz' % relation))\n",
    "    print('edge index laoded')\n",
    "    data = Data(x=features, edge_index=relation_edge_index, y=labels)\n",
    "    data_split = np.load(os.path.join(loadpath, 'data_split.npy'))\n",
    "    train_i, i = mode[0], mode[1]\n",
    "    if train_i == i:\n",
    "        data.train_mask, data.val_mask = generateMasks(len(labels), data_split, train_i, i)\n",
    "    else:\n",
    "        data.test_mask = generateMasks(len(labels), data_split, train_i, i)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43511c93",
   "metadata": {},
   "source": [
    "### create homodataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bbae31c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mode: (train_i, i)\n",
    "message block 0-train_i, as training dataset\n",
    "random selection from training dataset, as validation dataset\n",
    "other message blocks between train_i and i, having no labels\n",
    "message block i, as test dataset\n",
    "'''\n",
    "# 返回training, validation, test data\n",
    "def create_homodataset(loadpath, mode, valid_percent=0.2):\n",
    "    features = np.load(os.path.join(loadpath, 'features_embeddings.npy'))  # features embeddings\n",
    "    features = torch.FloatTensor(features)\n",
    "    print('features loaded')\n",
    "    labels = np.load(os.path.join(loadpath, 'labels.npy'))\n",
    "    print('labels loaded')\n",
    "    labels = torch.LongTensor(labels)\n",
    "    \n",
    "    data = Data(x=features, edge_index=None, y=labels)  # torch_geometric提供的图数据类型Data，x表示tensor矩阵，\n",
    "                                                        # 形状为[num_nodes, num_node_features]; \n",
    "                                                        # edge_index表示coo格式的图的边关系，形状为[2, num_edge]\n",
    "    data_split = np.load(os.path.join(loadpath, 'data_split.npy'))\n",
    "    # load number of message in each blocks\n",
    "    # e.g. data_split = [  500  ,   100, ...,  100]\n",
    "    #                    block_0  block_1    block_n\n",
    "    train_i, i = mode[0], mode[1]\n",
    "    if train_i == i:\n",
    "        data.train_mask, data.val_mask = generateMasks(len(labels), data_split, train_i, i, valid_percent)\n",
    "    else:\n",
    "        data.test_mask = generateMasks(len(labels), data_split, train_i, i)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "82a47b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11971, 18)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d86d2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac79406",
   "metadata": {},
   "source": [
    "### create_offline_homodataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "09409dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_offline_homodataset(loadpath, mode):\n",
    "    features = np.load(os.path.join(loadpath, 'features_embeddings.npy'))\n",
    "    features = torch.FloatTensor(features)\n",
    "    print('features loaded')\n",
    "    labels = np.load(os.path.join(loadpath, 'labels.npy'))\n",
    "    print('labels loaded')\n",
    "    labels = torch.LongTensor(labels)\n",
    "    data = Data(x=features, edge_index=None, y=labels)\n",
    "    data.train_mask, data.val_mask, data.test_mask = gen_offline_masks(len(labels))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b12a7a",
   "metadata": {},
   "source": [
    "### create_multi_relational_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "946dca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get edge_index_relation data\n",
    "def create_multi_relational_graph(loadpath, relations, mode):\n",
    "    multi_relation_edge_index = [torch.load(loadpath + '/edge_index_%s.pt' % relation) for relation in relations]\n",
    "    print('sparse trans...')\n",
    "    print('edge index loaded')\n",
    "    \n",
    "    return multi_relation_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "96c12141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [5],\n",
       "        [7],\n",
       "        [2]]),\n",
       " array([[0, 3, 1, 2]]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ix_([1,5,7,2],[0,3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e696c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_multi_relational_graph(loadpath, relations, mode):\n",
    "    for relation in relations:\n",
    "        relation_edge_index = sparse_trans(os.path.join(loadpath, str(mode[1]), 's_m_tid_%s_tid.npz' % relation))\n",
    "        torch.save(relation_edge_index, loadpath + '/' + str(mode[1]) + '/edge_index_%s.pt' % relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "70577d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f977bbf",
   "metadata": {},
   "source": [
    "### generateMasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7436d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回training，validation, test的索引indices\n",
    "def generateMasks(length, data_split, train_i, i, validation_percent=0.2, save_path=None, remove_absolete=2):\n",
    "    '''    \n",
    "    Intro:\n",
    "    This function generates train and validation indices for initial/maintenance epochs and test indices for inference(prediction) epochs\n",
    "    If remove_obsolete mode 0 or 1:\n",
    "    For initial/maintenance epochs:\n",
    "    - The first (train_i + 1) blocks (blocks 0, ..., train_i) are used as training set (with explicit labels)\n",
    "    - Randomly sample validation_percent of the training indices as validation indices\n",
    "    For inference(prediction) epochs:\n",
    "    - The (i + 1)th block (block i) is used as test set.\n",
    "    \n",
    "    Note that other blocks (block train_i + 1, ..., i - 1) are also in the graph (without explicit labels, only their features and structural info are leveraged)\n",
    "\n",
    "    :param length: the length of label list\n",
    "    :param data_split: loaded splited data (generated in custom_message_graph.py)\n",
    "    :param train_i, i: flag, indicating for initial/maintenance stage if train_i == i and inference stage for others\n",
    "    :param validation_percent: the percent of validation data occupied in whole dataset\n",
    "    :param save_path: path to save data\n",
    "    :param num_indices_to_remove: number of indices ought to be removed\n",
    "    :returns train indices, validation indices or test indices\n",
    "    '''\n",
    "    # step1: verify total number of nodes\n",
    "    assert length == data_split[i] # 500\n",
    "    \n",
    "    # step2.0: if is in initial/maintenance epochs, generate train and validation indices\n",
    "    if train_i == i:\n",
    "        # step3: randomly shuffle the graph indices\n",
    "        train_indices = torch.randperm(length)  # 返回一个随机打散的0-n-1 tensor数组\n",
    "        # step4: get total number of validation indices\n",
    "        n_validation_samples = int(length * validation_percent)\n",
    "        # step5: sample n_validation_samples validation indices and use the rest as training indices\n",
    "        validation_indices = train_indices[:n_validation_samples]\n",
    "        train_indices = train_indices[n_validation_samples:]\n",
    "        # step6: save indices\n",
    "        if save_path is not None:\n",
    "            torch.save(train_indices, save_path + '/train_indices.pt')\n",
    "            torch.save(validation_indices, save_path + '/validation_indices.pt')\n",
    "        return train_indices, validation_indices\n",
    "    # step2.1: if is in inference(prediction) epochs, generate test indices\n",
    "    else:\n",
    "        test_indices = torch.arange(0, (data_split[i]), dtype=torch.long)\n",
    "        if save_path is not None:\n",
    "            torch.save(test_indices, save_path + '/test_indices.pt')\n",
    "        return test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1b57ac2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98181995",
   "metadata": {},
   "source": [
    "### gen_offline_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ebd97508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_offline_masks(length, validation_percent=0.2, test_percent=0.1):\n",
    "    test_length = int(length * test_percent)\n",
    "    valid_length = int(length * validation_percent)\n",
    "    train_length = length - valid_length - test_length\n",
    "    \n",
    "    samples = torch.randperm(length)  # 返回随机打散的0~n-1的tensor数组\n",
    "    train_indices = samples[:train_length]\n",
    "    valid_indices = samples[train_length: train_length + valid_length]\n",
    "    test_indices = samples[train_length + valid_length:]\n",
    "    \n",
    "    return train_indices, valid_indices, test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d824b",
   "metadata": {},
   "source": [
    "### mysampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "feb9e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Optional, Tuple, NamedTuple, Union, Callable\n",
    "from scipy import sparse\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.loader import NeighborSampler, RandomNodeSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fcac323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeighborSampler返回结果：batch_size, n_id,adjs(edge_index,e_id,size)\n",
    "class MySampler(object):\n",
    "    def __init__(self, sampler) -> None:\n",
    "        super().__init__()\n",
    "        self.sampler = sampler\n",
    "    \n",
    "    def sample(self, multi_relational_edge_index: List[Tensor], node_idx, sizes, batch_size):\n",
    "        if self.sampler == 'RL_sampler':\n",
    "            return self._RL_sample(multi_relational_edge_index, node_idx, sizes, batch_size)\n",
    "        elif self.sampler == 'randdom_sampler':\n",
    "            return self._random_sample(multi_relational_edge_index, node_idx, batch_size)\n",
    "        elif self.sampler == 'const_sampler':\n",
    "            return self._const_sample(multi_relational_edge_index, node_idx, batch_size)\n",
    "    \n",
    "    def _RL_sample(self, multi_relational_edge_index: List[Tensor], node_idx, sizes, batch_size):\n",
    "        outs = []\n",
    "        all_n_ids = []\n",
    "        for id, edge_index in enumerate(multi_relational_edge_index):  # 返回数据和数据下标\n",
    "            loader = NeighborSampler(edge_index=edge_index, \n",
    "                                     sizes=sizes, \n",
    "                                     node_idx=node_idx, \n",
    "                                     return_e_id=False,\n",
    "                                     batch_size=batch_size, \n",
    "                                     num_workers=0)  \n",
    "            for id, (_, n_ids, adjs) in enumerate(loader):  # NeighborSampler返回结果：batch_size, n_id,adjs(edge_index,e_id,size)\n",
    "                outs.append(adjs)  # adjs包括：edge_index, bipartite子图中source节点到target节点的边，e_id是在原始图中的id，size是子图shape\n",
    "                all_n_ids.append(n_ids)  # n_ids是包含所有在L层卷积中遇到的节点的list，且target节点在n_ids前几位\n",
    "            \n",
    "            assert id == 0  # 断言，条件为false时触发，中断程序\n",
    "        return outs, all_n_ids\n",
    "    \n",
    "    def _random_sample(self, multi_relational_edge_index: List[Tensor], node_idx, batch_size):\n",
    "        outs = []\n",
    "        all_n_ids = []\n",
    "        sizes = [random.randint(10,100), random.randint(10,50)]\n",
    "        for edge_index in multi_relational_edge_index:\n",
    "            loader = NeighborSampler(edge_index=edge_index, sizes=sizes, node_idx=node_idx, return_e_id=False,\n",
    "                                    batch_size=batch_size, num_workers=0)\n",
    "            for id, (_, n_ids, adjs) in enumerate(loader):\n",
    "                outs.append(adjs)\n",
    "                all_n_ids.append(n_ids)\n",
    "            assert id == 0\n",
    "        return outs, all_n_ids\n",
    "\n",
    "    def _const_sample(self, multi_relational_edge_index: List[Tensor], node_idx, batch_size):\n",
    "        outs = []\n",
    "        all_n_ids = []\n",
    "        sizes = [25, 15]\n",
    "        for edge_index in multi_relational_edge_index:\n",
    "            loader = NeighborSampler(edge_index=edge_index, sizes=sizes, node_idx=node_idx, return_e_id=False,\n",
    "                                    batch_size=batch_size, num_workers=0)\n",
    "            for id, (_, n_ids, adjs) in enumerate(loader):\n",
    "                outs.append(adjs)\n",
    "                all_n_ids.append(n_ids)\n",
    "            assert id == 0\n",
    "        return outs, all_n_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37081a9",
   "metadata": {},
   "source": [
    "### save_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3dc97cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(extracted_features, save_path):\n",
    "    torch.save(extracted_features, save_path + '/final_embeddings.pt')\n",
    "    print('extracted features saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8789272a",
   "metadata": {},
   "source": [
    "## MarGNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2356cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import Tensor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38dd1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MarGNN model 返回node embedding representation\n",
    "class MarGNN(nn.Module):\n",
    "    def __init__(self, GNN_args, num_relations, inter_opt, is_shared=False):\n",
    "        super(MarGNN, self).__init__()\n",
    "        \n",
    "        self.num_relations = num_relations  \n",
    "        self.inter_opt = inter_opt\n",
    "        self.is_shared = is_shared\n",
    "        if not self.is_shared:\n",
    "            self.intra_aggs = torch.nn.ModuleList([Intra_AGG(GNN_args) for _ in range(self.num_relations)])\n",
    "        else:\n",
    "            self.intra_aggs = Intra_AGG(GNN_args) # shared parameters\n",
    "        \n",
    "        if self.inter_opt == 'cat_w_avg_mlp' or 'cat_wo_avg_mlp':\n",
    "            in_dim, hid_dim, out_dim, heads = GNN_args\n",
    "            mlp_args = self.num_relations * out_dim, out_dim\n",
    "            self.inter_agg = Inter_AGG(mlp_args)\n",
    "        else:\n",
    "            self.inter_agg = Inter_AGG()\n",
    "    \n",
    "    def forward(self, x, adjs, n_ids, device, RL_thresholds):\n",
    "        # RL_threshold: tensor([[.5], [.5], [.5]])\n",
    "        if RL_thresholds is None:\n",
    "            RL_thresholds = torch.FloatTensor([[1.], [1.], [1.]])\n",
    "        if not isinstance(RL_thresholds, Tensor):\n",
    "            RL_thresholds = torch.FloatTensor(RL_thresholds)\n",
    "        RL_thresholds = RL_thresholds.to(device)\n",
    "        \n",
    "        features = []\n",
    "        for i in range(self.num_relations):  \n",
    "            if not self.is_shared:\n",
    "                # print('Intra Aggregation of relation %d' % i)\n",
    "                features.append(self.intra_aggs[i](x[n_ids[i]], adjs[i], device))\n",
    "            else:\n",
    "                # shared parameters\n",
    "                # print('Shared Intra Aggregation ...')\n",
    "                features.append(self.intra_aggs(x[n_ids[i]], adjs[i], device))\n",
    "        \n",
    "        features = torch.stack(features, dim=0)\n",
    "        features = self.inter_agg(features, RL_thresholds, self.inter_opt)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0965f",
   "metadata": {},
   "source": [
    "## HeteGAT_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660589af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HeteGAT_multi((feat_dim, args.hidden_dim, args.out_dim, args.heads), \n",
    "                      num_relations=num_relations, inter_opt=args.inter_opt,is_shared=args.is_shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38afd574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteGAT_multi(BaseGAttN):\n",
    "    '''\n",
    "    # forward；model = HeteGAT_multi\n",
    "    logits, final_embedding, att_val = model.inference(ftr_in_list,  # list:3, tensor（1， 3025， 1870）\n",
    "                                                       nb_classes,   # 3\n",
    "                                                       nb_nodes,     # 3025\n",
    "                                                       is_train,     # bool\n",
    "                                                       attn_drop,    # tensor, ()\n",
    "                                                       ffd_drop,     # tensor, ()\n",
    "                                                        bias_mat_list=bias_in_list,  # list:2, tensor()\n",
    "                                                       hid_units=hid_units,   # hid_units:8\n",
    "                                                       n_heads=n_heads,       # n_heads: [8, 1]\n",
    "                                                       residual=residual,     # residual: False\n",
    "                                                       activation=nonlinearity)  # nonlinearity:tf.nn.elu\n",
    "    \n",
    "    model = HeteGAT_multi((feat_dim, args.hidden_dim, args.out_dim, args.heads), \n",
    "                      num_relations=num_relations, inter_opt=args.inter_opt,is_shared=args.is_shared)\n",
    "    '''\n",
    "    def inference(feat_dim, nb_classes, nb_nodes, training, attn_drop, ffd_drop,\n",
    "                  bias_mat_list, hid_units, n_heads, activation=tf.nn.elu, residual=False,\n",
    "                  mp_att_size=128):\n",
    "        embed_list = []\n",
    "        for features, bias_mat in zip(feat_dim, bias_mat_list):\n",
    "            attns = []\n",
    "            jhy_embeds = []\n",
    "            for _ in range(n_heads[0]):   # [8,1]\n",
    "                # multi-head attention 计算\n",
    "                attns.append(attn_head(features, bias_mat=bias_mat,\n",
    "                                              out_sz=hid_units[0], activation=activation,\n",
    "                                              in_drop=ffd_drop, coef_drop=attn_drop, residual=False))\n",
    "            h_1 = tf.concat(attns, axis=-1)\n",
    "\n",
    "            for i in range(1, len(hid_units)):\n",
    "                h_old = h_1\n",
    "                attns = []\n",
    "                for _ in range(n_heads[i]):\n",
    "                    attns.append(attn_head(h_1, bias_mat=bias_mat,\n",
    "                                                  out_sz=hid_units[i],\n",
    "                                                  activation=activation,\n",
    "                                                  in_drop=ffd_drop,\n",
    "                                                  coef_drop=attn_drop, residual=residual))\n",
    "                h_1 = tf.concat(attns, axis=-1)\n",
    "            embed_list.append(tf.expand_dims(tf.squeeze(h_1), axis=1))  # list:2. 其中每个元素tensor, (3025, 1, 64)\n",
    "\n",
    "        multi_embed = tf.concat(embed_list, axis=1)   # tensor, (3025, 2, 64)\n",
    "        # attention输出：tensor(3025, 64)、softmax概率\n",
    "        final_embed, att_val = SimpleAttLayer(multi_embed, \n",
    "                                              mp_att_size,\n",
    "                                              time_major=False,\n",
    "                                              return_alphas=True)\n",
    "\n",
    "        out = []\n",
    "        for i in range(n_heads[-1]):  # 1\n",
    "            # 用于添加一个全连接层(input, output) -> (3025, 3)\n",
    "            out.append(tf.compat.v1.layers.dense(final_embed, nb_classes, activation=None))  \n",
    "        #     out.append(attn_head(h_1, bias_mat=bias_mat,\n",
    "        #                                 out_sz=nb_classes, activation=lambda x: x,\n",
    "        #                                 in_drop=ffd_drop, coef_drop=attn_drop, residual=False))\n",
    "        logits = tf.add_n(out) / n_heads[-1]  # add_n是列表相加。tensor,(3025, 3)\n",
    "        # logits_list.append(logits)\n",
    "        print('de')\n",
    "\n",
    "        logits = tf.expand_dims(logits, axis=0)  # (1, 3025, 3)\n",
    "        # attention通过全连接层预测(1, 3025, 3)、attention final_embedding tensor(3025, 64)、attention 概率\n",
    "        return logits, final_embed, att_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e77a91",
   "metadata": {},
   "source": [
    "## FinEvent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b044c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import gc  # garbage cleaning package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "505fb925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models\\\\FinEvent Models'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "60f4e0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(n_epochs=50, window_size=3, patience=5, margin=3, lr=0.001, batch_size=100, hidden_dim=128, out_dim=64, heads=4, validation_percent=0.2, use_hardest_neg=False, is_shared=False, inter_opt='cat_w_avg', is_initial=True, sampler='RL_sampler', cluster_type='kmeans', threshold_start0=[[0.2], [0.2], [0.2]], RL_step0=0.02, RL_start0=0, eps_start=0.001, eps_step=0.02, min_Pts_start=2, min_Pts_step=1, use_cuda=True, data_path='D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/offline dataset/', mask_path=None, log_interval=10)\n"
     ]
    }
   ],
   "source": [
    "args = args_register()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8391b856",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class FinEvent():\n",
    "    def __init__(self, args) -> None:\n",
    "        # register args\n",
    "        self.args = args\n",
    "    \n",
    "    def inference(self,  # inference = prediction\n",
    "                 train_i, i,\n",
    "                 metrics,\n",
    "                 embedding_save_path,\n",
    "                 loss_fn,\n",
    "                 model: HeteGAT_multi, # MarGNN,  # HeteGAT\n",
    "                 RL_thresholds=None,\n",
    "                 loss_fn_dgi=None):\n",
    "        # make dir for graph i\n",
    "        # ./incremental_0808//embeddings_0403005348/block_xxx\n",
    "        save_path_i = embedding_save_path + '/block_' + str(i)\n",
    "        if not os.path.isdir(save_path_i):\n",
    "            os.mkdir(save_path_i)\n",
    "         \n",
    "        # load data\n",
    "        relation_ids: List[str] = ['entity', 'userid', 'word']  # typing package\n",
    "        homo_data = create_homodataset(self.args.data_path, [train_i, i], self.args.validation_percent) # get training,validation,test数据\n",
    "        multi_r_data = create_multi_relational_graph(self.args.data_path, relation_ids, [train_i, i])  # load relation data\n",
    "        num_relations = len(multi_r_data)\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() and self.args.use_cuda else 'cpu')\n",
    "        \n",
    "        # input dimension (300 in our paper)\n",
    "        features = homo_data.x  # x是features embeddings\n",
    "        feat_dim = features.size(1)\n",
    "        \n",
    "        # prepare graph configs for node filtering\n",
    "        if self.args.is_initial:\n",
    "            print('prepare node configures...')\n",
    "            pre_node_dist(multi_r_data, homo_data.x, save_path_i)\n",
    "            filter_path = save_path_i\n",
    "        else:\n",
    "            filter_path = self.args.data_path + str(i)\n",
    "        \n",
    "        if model is None:\n",
    "            assert 'Cannot fine pre-trained model'\n",
    "        \n",
    "        # directly predict\n",
    "        message = '\\n-----------------Directly predict on block' + str(i) + '-----------------\\n'\n",
    "        print(message)\n",
    "        print('RL Threshold using in this block:', RL_thresholds)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        test_indices, labels = homo_data.test_mask, homo_data.y\n",
    "        test_num_samples = test_indices.size(0)\n",
    "        \n",
    "        sampler = MySampler(self.args.sampler)\n",
    "        \n",
    "        # filter neighbor in advance to fit with neighbor sampling\n",
    "        filtered_multi_r_data = RL_neighbor_filter(multi_r_data, RL_thresholds, filter_path) if RL_thresholds is not None and \\\n",
    "                                self.args.sampler == 'RL_sampler' else multi_r_data\n",
    "        \n",
    "        # batch testing\n",
    "        extract_features = torch.FloatTensor([])\n",
    "        num_batches = int(test_num_samples / self.args.batch_size) + 1\n",
    "        with torch.no_grad():  # 在该模块下，所有计算得出的tensor的requires_grad都自动设置为False，不自动反向传播求导\n",
    "            for batch in range(num_batches):\n",
    "                start_batch = time.time()\n",
    "                \n",
    "                # split batch\n",
    "                i_start = self.args.batch_size * batch\n",
    "                i_end = min((batch + 1) * self.args.batch_size, test_num_samples)\n",
    "                batch_nodes = test_indices[i_start:i_end]\n",
    "                \n",
    "                # sampling neighbors of batch nodes\n",
    "                adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx= batch_nodes, sizes=[-1, -1], \n",
    "                                             batch_size= self.args.batch_size)\n",
    "                pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "                batch_seconds_spent = time.time() - start_batch\n",
    "                \n",
    "                # for we haven't shuffle the test indices(see utils.py)\n",
    "                # the output embeddings can be simply stacked together\n",
    "                extract_features = torch.cat((extract_features, pred.cpu().detach()), dim=0)\n",
    "                \n",
    "                del pred\n",
    "                gc.collect()  # 清除缓存\n",
    "        \n",
    "        save_embeddings(extract_features, save_path_i)\n",
    "        # 返回评价指标nmi，ami，ari\n",
    "        test_nmi = evaluate(extract_features,\n",
    "                           labels,\n",
    "                           indices=test_indices,\n",
    "                           epoch=-1, # just for test\n",
    "                           num_isolated_nodes=0,\n",
    "                           save_path= save_path_i,\n",
    "                           is_validation= False,\n",
    "                           cluster_type= self.args.cluster_type)\n",
    "        del homo_data, multi_r_data, features, filtered_multi_r_data\n",
    "        torch.cuda.empty_cache()  # 释放显存\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    # train on initial/maintenance graphs, t==0 or t % window_size == 0 in this paper\n",
    "    def initial_maintain(self,\n",
    "                        train_i, i,\n",
    "                        metrics,\n",
    "                        embedding_save_path,\n",
    "                        loss_fn,\n",
    "                        model=None,\n",
    "                        loss_fn_dgi=None):\n",
    "        '''\n",
    "        :param i:\n",
    "        :param data_split:\n",
    "        :param metrics:\n",
    "        :param embedding_save_path:\n",
    "        :param loss_fn:\n",
    "        :param model:\n",
    "        :param loss_fn_dgi:\n",
    "        :return:\n",
    "        '''\n",
    "        # make dir for graph i\n",
    "        # ./incremental_0808//embeddings_0403005348/block_xxx\n",
    "        save_path_i = embedding_save_path + '/block_' + str(i)\n",
    "        if not os.path.isdir(save_path_i):\n",
    "            os.mkdir(save_path_i)\n",
    "        \n",
    "        # load data\n",
    "        relation_ids: List[str] = ['entity', 'userid', 'word']\n",
    "        homo_data = create_homodataset(self.args.data_path, [train_i, i], self.args.validation_percent)\n",
    "        multi_r_data = create_multi_relational_graph(self.args.data_path, relation_ids, [train_i, i])  # relation data\n",
    "        num_relations = len(multi_r_data)\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() and self.args.use_cuda else 'cpu')\n",
    "        \n",
    "        # input dimension (300 in our paper)\n",
    "        num_dim = homo_data.x.size(0)  # embeddings num\n",
    "        feat_dim = homo_data.x.size(1) # embeddings dimension\n",
    "        \n",
    "        # prepare graph configs for node filtering\n",
    "        if self.args.is_initial:\n",
    "            print('prepare node %configures...')\n",
    "            cal_similarity_node_edge(multi_r_data, homo_data.x, save_path_i)\n",
    "            filter_path = save_path_i\n",
    "        else:\n",
    "            filter_path = self.args.data_path + str(i)\n",
    "        \n",
    "        if model is None: # pre-training stage in our paper\n",
    "            # print('Pre-Train Stage')\n",
    "            model = MarGNN((feat_dim, self.args.hidden_dim, self.args.out_dim, self.args.heads),\n",
    "                          num_relations=num_relations, inter_opt=self.args.inter_opt, is_shared=self.args.is_shared)\n",
    "        \n",
    "        # define sampler\n",
    "        sampler = MySampler(self.args.sampler)  # top-p neighbors\n",
    "        # load model to device\n",
    "        model.to(device)\n",
    "        \n",
    "        # initialize RL thresholds\n",
    "        RL_thresholds = torch.FloatTensor(self.args.threshold_start0)  # [[0.2],[0.2],[0.2]]\n",
    "        \n",
    "        # define optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr=self.args.lr, weight_decay=1e-4)\n",
    "        \n",
    "        # record training log\n",
    "        message = '\\n------------- Start initial training / maintaining using block ' + str(i) + '----------\\n'\n",
    "        print(message)\n",
    "        with open(save_path_i + '/log.txt', 'a') as f:\n",
    "            f.write(message)\n",
    "        \n",
    "        # record the highest validation nmi ever got for early stopping\n",
    "        best_vali_nmi = 1e-9\n",
    "        best_epoch = 0\n",
    "        wait = 0\n",
    "        # record validation nmi of all epochs before early stop\n",
    "        all_vali_nmi = []\n",
    "        # record the time spent in seconds on each batch of all training/maintaining epochs\n",
    "        seconds_train_batches = []\n",
    "        # record the time spent in mins on each epoch\n",
    "        mins_train_epochs = []\n",
    "        \n",
    "        # step13: start epoch training\n",
    "        for epoch in range(self.args.n_epochs):  # n_epochs=50\n",
    "            start_epoch = time.time()\n",
    "            losses = []\n",
    "            total_loss = 0.0\n",
    "            \n",
    "            for metric in metrics:\n",
    "                metric.reset()\n",
    "                \n",
    "            # Multi-Agent\n",
    "            \n",
    "            # filter neighbor in advance to fit with neighbor sampling\n",
    "            if epoch >= self.args.RL_start0 and self.args.sampler == 'RL_sampler':  # RL_start0=0\n",
    "                filtered_multi_r_data = RL_neighbor_filter(multi_r_data, RL_thresholds, filter_path) \n",
    "            else:\n",
    "                filtered_multi_r_data = multi_r_data\n",
    "                \n",
    "            model.train()\n",
    "            train_num_samples, valid_num_samples = homo_data.train_mask.size(0), homo_data.val_mask.size(0)\n",
    "            all_num_samples = train_num_samples + valid_num_samples\n",
    "            \n",
    "            # mini-batch training------------------------------------------------------------------\n",
    "            num_batches = int(train_num_samples / self.args.batch_size) + 1  # batch_size=100\n",
    "            for batch in range(num_batches):\n",
    "                start_batch = time.time()\n",
    "                # split batch\n",
    "                i_start = self.args.batch_size * batch\n",
    "                i_end = min((batch + 1) * self.args.batch_size, train_num_samples)\n",
    "                batch_nodes = homo_data.train_mask[i_start:i_end]  # 从training data中取出mini-batch用于训练\n",
    "                batch_labels = homo_data.y[batch_nodes]\n",
    "                \n",
    "                # sampling neighobrs from mini-batch nodes \n",
    "                adjs, n_ids = sampler.sample(filtered_multi_r_data, node_ids=batch_nodes, sizes=[-1,-1], batch_size=self.args.batch_size)\n",
    "                \n",
    "                optimizer.zero_grad() \n",
    "                \n",
    "                pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "                \n",
    "                loss_outputs = loss_fn(pred, batch_labels)\n",
    "                \n",
    "                loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                for metric in metrics:\n",
    "                    metric(pred, batch_labels, loss_outputs)\n",
    "                    \n",
    "                if batch % self.args.log_interval == 0:\n",
    "                    message = 'Train: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(batch * self.args.batch_size, train_num_samples, 100. * batch / ((train_num_samples // self.args.batch_size) + 1), np.mean(losses))\n",
    "                    \n",
    "                    for metric in metrics:\n",
    "                        message += '\\t{}: {:.4f}'.format(metric.name(), metric.value())\n",
    "                    \n",
    "                    with open(save_path_i + '/log.txt', 'a') as f:\n",
    "                        f.write(message)\n",
    "                    losses = []\n",
    "                del pred, loss_outputs\n",
    "                gc.collect()\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()  # 更新参数\n",
    "                \n",
    "                batch_seconds_spent = time.time() - start_batch\n",
    "                seconds_train_batches.append(batch_seconds_spent)\n",
    "                \n",
    "                del pred\n",
    "                gc.collect()\n",
    "            \n",
    "            # step 14: print loss\n",
    "            total_loss /= (batch + 1)\n",
    "            message = 'Epoch: {}/{}. Average loss: {:.4f}'.format(epoch, self.args.n_epochs, total_loss)\n",
    "            for metric in metrics:\n",
    "                message += '\\t{}: {:.4f}'.format(metric.name(), metric.value())\n",
    "            mins_spent = (time.time() - start_epoch) / 60\n",
    "            message += '\\nThis epoch took {:.2f} mins'.format(mins_spent)\n",
    "            message += '\\n'\n",
    "            print(message)\n",
    "            \n",
    "            with open(save_path_i + '/log.txt', 'a') as f:\n",
    "                f.write(message)\n",
    "            mins_train_epochs.append(mins_spent)\n",
    "            \n",
    "            # validation-------------------------------------------------------------------------\n",
    "            # infer the representation of all tweets\n",
    "            model.eval()\n",
    "            \n",
    "            # we recommand to forward all nodes and select the validation indices instead\n",
    "            extract_features = torch.FloatTensor([])\n",
    "            \n",
    "            num_batches = int(all_num_samples / self.args.batch_size) + 1\n",
    "            \n",
    "            # all mask are then splited into mini-batch in order\n",
    "            all_mask = torch.arange(0, num_dim, dtype=torch.long)\n",
    "            \n",
    "            for batch in range(num_batches):\n",
    "                start_batch = time.time()\n",
    "                # split batch\n",
    "                i_start = self.args.batch_size * batch\n",
    "                i_end = min((batch+1) * self.args.batch_size, all_num_samples)\n",
    "                batch_nodes = all_mask[i_start:i_end]  # \n",
    "                batch_labels = homo_data.y[batch_nodes]\n",
    "                \n",
    "                # sampling neighbors of batch nodes\n",
    "                adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx=batch_nodes, sizes=[-1,-1], batch_size=self.args.batch_size)\n",
    "                \n",
    "                pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "                \n",
    "                extract_features = torch.cat((extract_features, pred.cpu().detach()), dim=0)\n",
    "                del pred\n",
    "                gc.collect()\n",
    "            # save_embeddings(extract_reatures, save_path_i)\n",
    "            # evaluate the model: conduct kMeans clustering on the validation and report NMI\n",
    "            validation_nmi = evaluate(extract_features[homo_data.val_mask],\n",
    "                                     homo_data.y,\n",
    "                                     epoch=epoch,\n",
    "                                     num_isolated_nodes=0,\n",
    "                                     save_path=save_path_i,\n",
    "                                     is_validation=True,\n",
    "                                     cluster_type=self.args.cluster_type)\n",
    "            all_vali_nmi.append(validation_nmi)\n",
    "            \n",
    "            # step16: early stop\n",
    "            if validation_nmi > best_vali_nmi:\n",
    "                best_vali_nmi = validation_nmi\n",
    "                best_epoch = epoch\n",
    "                wait = 0\n",
    "                # save model\n",
    "                model_path = save_path_i + '/models'\n",
    "                if (epoch == 0) and (not os.path.isdir(model_path)):\n",
    "                    os.mkdir(model_path)\n",
    "                p = model_path + '/best.pt'\n",
    "                torch.save(model.state_dict(), p)  # 保存模型，OrderDict存储网络结构的名字和对应的参数\n",
    "                print('Best model saved after epoch ', str(epoch))\n",
    "            else:\n",
    "                wait += 1\n",
    "            if wait >= self.args.patience:\n",
    "                print('Saved all_mins_spent')\n",
    "                print('Early stopping at epoch ', str(epoch))\n",
    "                print('Best model was at epoch ', str(best_epoch))\n",
    "                break\n",
    "            # end one epoch\n",
    "        \n",
    "        # save all validation mi\n",
    "        np.save(save_path_i + '/all_vali_nmi.npy', np.asarray(all_vali_nmi))\n",
    "        # save time spent on epochs\n",
    "        np.save(save_path_i + '/mins_train_epochs.npy', np.asarray(mins_train_epochs))\n",
    "        print('Saved mins_train_epochs')\n",
    "        # save time spent on batches\n",
    "        np.save(save_path_i + '/seconds_train_batches.npy', np.asarray(seconds_train_batches))\n",
    "        print('Best model loaded.')\n",
    "        \n",
    "        del homo_data, multi_r_data\n",
    "        torch.cuda.empty_cache()  # 释放显存\n",
    "        \n",
    "        return model, RL_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "24e986c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 3, 1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e48b2eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0], dtype=int64),)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2,43,2,42,12,454])[0]\n",
    "np.where(a<5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcb96f8",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "142b5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility，功能\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dd4a1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交集\n",
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525cd340",
   "metadata": {},
   "source": [
    "### run kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "76afe613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans(extract_features, extract_labels, indices, isoPath=None):\n",
    "    # extract the features and labels of the test tweets\n",
    "    if isoPath is not None:\n",
    "        # Remove isolated points\n",
    "        temp = torch.load(isoPath)\n",
    "        temp = temp.cpu().detach().numpy()  # detach()阻断反向传播，返回值为tensor；numpy()将tensor转换为numpy\n",
    "        non_isolated_index = list(np.where(temp != 1)[0]) # np.where返回符合条件元素的索引index\n",
    "        indices = intersection(indices, non_isolated_index)  # 取交集\n",
    "    # Extract labels\n",
    "    extract_labels = extract_labels.cpu().numpy()\n",
    "    labels_true = extract_labels[indices]\n",
    "    \n",
    "    # Extrac features\n",
    "    X = extract_features.cpu().detach().numpy()\n",
    "    assert labels_true.shape[0] == X.shape[0]  # assert断言，在判断式false时触发异常\n",
    "    n_test_tweets = X.shape[0]  # 100\n",
    "    \n",
    "    # Get the total number of classes\n",
    "    n_classes = len(set(labels_true.tolist()))  # unique()和nunique()不香吗？\n",
    "    \n",
    "    # k-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_classes, random_state=0).fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    nmi = metrics.normalized_mutual_info_score(labels_true, labels)  # 计算归一化互信息\n",
    "    ami = metrics.adjusted_mutual_info_score(labels_true, labels)\n",
    "    ari = metrics.adjusted_rand_score(labels_true, labels)  # 计算兰德系数\n",
    "    \n",
    "    # Return number of test tweets, number of classes covered by the test tweets, and KMeans clustering NMI\n",
    "    return n_test_tweets, n_classes, nmi, ami, ari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c9b60",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b2f25",
   "metadata": {},
   "source": [
    "### metrics operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ce1718f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d7d6ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, outputs, target, loss):\n",
    "        raise NotImplementedError  # 没有重写，就会报错\n",
    "    \n",
    "    def reset(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def value(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def name(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7a5ca",
   "metadata": {},
   "source": [
    "#### accumulate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "531135fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 累加平均metrics\n",
    "class AccumulateAccuracy(Metric):\n",
    "    '''\n",
    "    works with classification model\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.correct = 0\n",
    "        self.total = 0\n",
    "    \n",
    "    def __call__(self, outputs, target, loss):\n",
    "        pred = outputs[0].data.max(1, keepdim=True)[1]\n",
    "        self.correct += pred.eq(target[0].data.view_as(pred)).cpu().sum()\n",
    "        self.total += target[0].size(0)\n",
    "        return self.value()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.correct = 0\n",
    "        self.total = 0\n",
    "    \n",
    "    def value(self):\n",
    "        return 100 * float(self.correct) / self.total\n",
    "    \n",
    "    def name(self):\n",
    "        return 'Accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f913ab",
   "metadata": {},
   "source": [
    "#### average metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e64e0f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 非零平均\n",
    "class AverageNonzeroTripletsMetric(Metric):\n",
    "    '''\n",
    "    Counts average number of nonzero triplets found in minibatches\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.values = []\n",
    "    \n",
    "    def __call__(self, outputs, target, loss):\n",
    "        self.values.append(loss[1])\n",
    "        return self.value()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.values = []\n",
    "    \n",
    "    def value(self):\n",
    "        return np.mean(self.values)\n",
    "    \n",
    "    def name(self):\n",
    "        return 'Average nonzero triplets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f1e24a",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "29dad01a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def evaluate(extract_features, extract_labels, indices, epoch, num_isolated_nodes, save_path,\n",
    "             is_validation=True, cluster_type='kmeans'):\n",
    "    message = ''\n",
    "    message += '\\nEpoch '\n",
    "    message += str(epoch)\n",
    "    message += '\\n'\n",
    "    \n",
    "    # with isolated nodes\n",
    "    if cluster_type == 'kmeans':\n",
    "        n_tweets, n_classes, nmi, ami, ari = run_kmeans(extract_features, extract_labels, indices)\n",
    "    elif cluster_type == 'dbscan':\n",
    "        pass\n",
    "    \n",
    "    if is_validation:\n",
    "        mode = 'validation'\n",
    "    else:\n",
    "        mode = 'test'\n",
    "    message += '\\tNumber of ' + mode + ' tweets: '\n",
    "    message += str(n_tweets)\n",
    "    message += '\\n\\tNumber of classes covered by ' + mode + ' tweets: '\n",
    "    message += str(n_classes)\n",
    "    message += '\\n\\t' + mode + ' NMI: '\n",
    "    message += str(nmi)\n",
    "    message += '\\n\\t' + mode + 'AMi: '\n",
    "    message += str(ami)\n",
    "    message += '\\n\\t' + mode + 'ARI'\n",
    "    message += str(ari)\n",
    "    if cluster_type == 'dbscan':\n",
    "        message += '\\n\\t' + mode + ' best_eps: '\n",
    "        message += '\\n\\t' + mode + ' best_min_Pts: '\n",
    "    \n",
    "    if num_isolated_nodes != 0:\n",
    "        # without isolated nodes\n",
    "        message += '\\n\\tWithout isolated nodes:'\n",
    "        n_tweets, n_classes, nmi, ami, ari = run_kmeans(extract_features, extract_labels, indices, \n",
    "                                                       save_path + '/isolated_nodes.pt')\n",
    "        message += '\\tNumber of ' + mode + 'tweets: '\n",
    "        message += str(n_tweets)\n",
    "        message += '\\n\\tNumber of classes covered by ' + mode + ' tweets'\n",
    "        message += str(n_classes)\n",
    "        message += '\\n\\t' + mode + 'NMI: '\n",
    "        message += str(nmi)\n",
    "        message += '\\n\\t' + mode + 'AMI: '\n",
    "        message += str(ami)\n",
    "        message += '\\n\\t' + mode + 'ARI: '\n",
    "        message += str(ari)\n",
    "    message += '\\n'\n",
    "    \n",
    "    with open(save_path + '/evaluate.txt', 'a') as f:\n",
    "        f.write(message)\n",
    "    print(message)\n",
    "    \n",
    "    np.save(save_path + '/%s_metric.npy' % mode, np.asarray([nmi, ami, ari]))\n",
    "    if is_validation:\n",
    "        return nmi\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba64d0f",
   "metadata": {},
   "source": [
    "# Run_FinEvent_Incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ff8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "step 1. run utils/generate_initial_features.py to generate the initial features for the messages\n",
    "\n",
    "step 2. run utils/custom_message_graph.py to construct incremental message graphs. To construct small message graphs for test purpose, set test=True when calling construct_incremental_dataset_0922(). To use all the messages (see Appendix of the paper for a statistic of the number of messages in the graphs), set test=False.\n",
    "\n",
    "step 3. run utils/save_edge_index.py in advance to acclerate the training process.\n",
    "\n",
    "step 4. run main.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e0aff267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json  # 轻量级的数据交换格式，易于阅读和编写\n",
    "import argparse  # 用于更方便地进行超参数的保存和修改\n",
    "import torch\n",
    "\n",
    "from time import localtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a4b4b7",
   "metadata": {},
   "source": [
    "## set paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ccf6d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_register():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_epochs', default=50, type=int, help='Number of initial-training/maintenance-training epochs.')\n",
    "    parser.add_argument('--window_size', default=3, type=int, help='Maintain the model after predicting window_size blocks.')\n",
    "    parser.add_argument('--patience', default=5, type=int, help='Early stop if performance did not improve in the last patience epochs.')\n",
    "    \n",
    "    parser.add_argument('--margin', default=3, type=float, help='Margin for computing triplet losses')\n",
    "    parser.add_argument('--lr', default=1e-3, type=float, help='Learning rate')\n",
    "    parser.add_argument('--batch_size', default=100, type=int, help='Batch size (number of nodes sampled to compute triplet loss in each batch)')\n",
    "    \n",
    "    parser.add_argument('--hidden_dim', default=128, type=int, help='Hidden dimension')\n",
    "    parser.add_argument('--out_dim', default=64, type=int, help='Output dimension of tweet representations')\n",
    "    parser.add_argument('heads', default=4, type=int, help='Number of heads used in GAT')\n",
    "    parser.add_argument('--validation_percent', default=0.2, type=float, help='Percentage of validation nodes(tweets)')\n",
    "    parser.add_argument('--use_hardest_neg', dest='user_hardes_neg', default=False, action='store_true', \n",
    "                       help='If true, use hardest negative messages to form triplets. Otherwise use random ones')\n",
    "    parser.add_argument('--is_shared', default=False)\n",
    "    parser.add_argument('--inter_opt', default='cat_w_avg')\n",
    "    parser.add_argument('--is_initial', default=False)\n",
    "    parser.add_argument('--sampler', default='RL_sampler')\n",
    "    parser.add_argument('--cluster_type', default='kmeans', help='Types of clustering algorithms') # DBSCAN\n",
    "    \n",
    "    # RL-0\n",
    "    parser.add_argument('--threshod_start0', default=[[0.2],[0.2],[0.2]], type=float, \n",
    "                        help='The initial value of filter threshold for state1 or state3')\n",
    "    parser.add_argument('--RL_step0', default=0.02, type=float, help='The step size of RL for state1 or state3')\n",
    "    parser.add_argument('--RL_start0', default=0, type=int, help='The starting epoch of RL for state1 or state3')\n",
    "    \n",
    "    # RL-1\n",
    "    parser.add_argument('--eps_start', default=0.001, type=float, help='The initial value of the eps for state2')\n",
    "    parser.add_argument('--eps_step', default=0.02, type=float, help='The step size of eps for state2')\n",
    "    parser.add_argument('--min_Pts_start', default=2, type=int, help='The initial value of the min_Pts for state2')\n",
    "    parser.add_argument('--min_Pts_step', default=1, type=int, help='The step size of min_Pts for state2')\n",
    "    \n",
    "    # other arguments\n",
    "    parser.add_argument('--user_cuda', dest='use_cuda', default=True, action='store_true', help='Use cuda')\n",
    "    parser.add_argument('--data_path', default='./incremental_0502/', type=str, help='Path of features, labels and edges')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--mask_path', default=None, type=str, help='File path that contains the training, validation and test masks')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--log_interval', default=10, type=int, help='Log interval')\n",
    "    args = parser.parse_args()  # 解析参数\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbccc46",
   "metadata": {},
   "source": [
    "## run incremental_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "78c1f8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/offline dataset/'"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "67e60b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n",
      "embedding save path:  D:\\PycharmProjects\\GNN_Event_Detection_models/result/FinEvent result/offline dataset//offline_embeddings\n",
      "Batch Size: 100\n",
      "Intra Agg Mode: False\n",
      "Inter Agg Mode: cat_w_avg\n",
      "Reserve node config? True\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'AverageNonzeroTriplesMetric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [415]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m OnlineTripletLoss(args\u001b[38;5;241m.\u001b[39mmargin, RandomNegativeTripletSelector(args\u001b[38;5;241m.\u001b[39mmargin))\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# define metrics\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m BCL_metrics \u001b[38;5;241m=\u001b[39m [\u001b[43mAverageNonzeroTriplesMetric\u001b[49m()]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# define detection stage\u001b[39;00m\n\u001b[0;32m     39\u001b[0m Streaming \u001b[38;5;241m=\u001b[39m FinEvent(args)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AverageNonzeroTriplesMetric' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # define args\n",
    "    args = args_register()\n",
    "    \n",
    "    # check CUDA\n",
    "    print('Using CUDA:', torch.cuda.is_available())\n",
    "    \n",
    "    # create working path\n",
    "#     embedding_save_path = args.data_path + '/embeddings_' + strftime(\"%m%d%H%M%S\", localtime())\n",
    "    embedding_save_path = args.data_path + '/offline_embeddings'\n",
    "    os.mkdir(embedding_save_path)\n",
    "    print('embedding save path: ', embedding_save_path)\n",
    "    \n",
    "    # record hyper-parameters\n",
    "    with open(embedding_save_path + '/args.txt', 'w') as f:\n",
    "        json.dump(args.__dict__, f, indent=2)\n",
    "    \n",
    "    print('Batch Size:', args.batch_size)\n",
    "    print('Intra Agg Mode:', args.is_shared)\n",
    "    print('Inter Agg Mode:', args.inter_opt)\n",
    "    print('Reserve node config?', args.is_initial)\n",
    "    \n",
    "    # load number of messages in each blocks\n",
    "    # e.g. data_split = [  500  ,   100, ...,  100]\n",
    "    #                    block_0  block_1    block_n\n",
    "    data_split = np.load(args.data_path + '/data_split.npy')\n",
    "    \n",
    "    # define loss function\n",
    "    # contrastive loss in our paper\n",
    "    if args.use_hardest_neg:\n",
    "        loss_fn = OnlineTripletLoss(args.margin, HardestNegativeTripletSelector(args.margin))\n",
    "    else:\n",
    "        loss_fn = OnlineTripletLoss(args.margin, RandomNegativeTripletSelector(args.margin))\n",
    "        \n",
    "    # define metrics\n",
    "    BCL_metrics = [AverageNonzeroTriplesMetric()]\n",
    "    \n",
    "    # define detection stage\n",
    "    Streaming = FinEvent(args)\n",
    "    \n",
    "    # pre-train stage: train on initial graph\n",
    "    train_i = 0\n",
    "    model, RL_thresholds = Streaming.initial_maintain(train_i = train_i,\n",
    "                                                     i = 0,\n",
    "                                                     metrics = BCL_metrics, \n",
    "                                                     embedding_save_path = embedding_save_path,\n",
    "                                                     loss_fn = loss_fn,\n",
    "                                                     model = None)\n",
    "    \n",
    "    # detection-maintenance stage: incremental training and detection\n",
    "    for i in range(1, data_split.shape[0]):\n",
    "        # infer every block\n",
    "        model = Streaming.inference(train_i=train_i,\n",
    "                                   i=i,\n",
    "                                   metrics=BCL_metrics,\n",
    "                                   embedding_save_path=embedding_save_path,\n",
    "                                   loss_fn=loss_fn,\n",
    "                                   model=model,\n",
    "                                   RL_thresholds=RL_thresholds)\n",
    "        \n",
    "        # maintenance in window size and desert the last block\n",
    "        if i % args.window_size == 0 and i != data_split.shape[0] -1:\n",
    "            model, RL_thresholds = Streaming.initial_maintain(train_i=train_i,\n",
    "                                                             i=i,\n",
    "                                                             metrics=BCL_metrics,\n",
    "                                                             embedding_save_path=embedding_save_path,\n",
    "                                                             loss_fn=loss_fn,\n",
    "                                                             model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823d054",
   "metadata": {},
   "source": [
    "# Run_FinEvent_Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdaee841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstep 1. run utils/generate_initial_features.py to generate the initial features for the messages\\n\\nstep 2. run utils/custom_message_graph.py to construct incremental message graphs. To construct small message graphs for test purpose, set test=True when calling construct_incremental_dataset_0922(). To use all the messages (see Appendix of the paper for a statistic of the number of messages in the graphs), set test=False.\\n\\nstep 3. run utils/save_edge_index.py in advance to acclerate the training process.\\n\\nstep 4. run offline.py\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "step 1. run utils/generate_initial_features.py to generate the initial features for the messages\n",
    "\n",
    "step 2. run utils/custom_message_graph.py to construct incremental message graphs. To construct small message graphs for test purpose, set test=True when calling construct_incremental_dataset_0922(). To use all the messages (see Appendix of the paper for a statistic of the number of messages in the graphs), set test=False.\n",
    "\n",
    "step 3. run utils/save_edge_index.py in advance to acclerate the training process.\n",
    "\n",
    "step 4. run offline.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "802957b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "from time import localtime, strftime  # strftime() 函数用于格式化时间，返回以可读字符串表示的当地时间\n",
    "\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "import time \n",
    "from typing import List, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0185ca5",
   "metadata": {},
   "source": [
    "## define paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb42f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_register():\n",
    "    parser = argparse.ArgumentParser()  # 创建参数对象\n",
    "    # 添加参数\n",
    "    parser.add_argument('--n_epochs', default=50, type=int, help='Number of initial-training/maintenance-training epochs.')\n",
    "    parser.add_argument('--window_size', default=3, type=int, help='Maintain the model after predicting window_size blocks.')\n",
    "    parser.add_argument('--patience', default=5, type=int, help='Early stop if perfermance did not improve in the last patience epochs.')\n",
    "    parser.add_argument('--margin', default=3, type=float, help='Margin for computing triplet losses')\n",
    "    parser.add_argument('--lr', default=1e-3, type=float, help='Learning rate')\n",
    "    \n",
    "    parser.add_argument('--batch_size', default=100, type=int, help='Batch size (number of nodes sampled to compute triplet loss in each batch)')\n",
    "    parser.add_argument('--hidden_dim', default=128, type=int, help='Hidden dimension')\n",
    "    parser.add_argument('--out_dim', default=64, type=int, help='Output dimension of tweet representation')\n",
    "    parser.add_argument('--heads', default=4, type=int, help='Number of heads used in GAT')\n",
    "    parser.add_argument('--validation_percent', default=0.2, type=float, help='Percentage of validation nodes(tweets)')\n",
    "    parser.add_argument('--use_hardest_neg', dest='use_hardest_neg', default=False, action='store_true', \n",
    "                        help='If true, use hardest negative messages to form triplets. Otherwise use random ones')\n",
    "    parser.add_argument('--is_shared', default=False)\n",
    "    parser.add_argument('--inter_opt', default='cat_w_avg')\n",
    "    parser.add_argument('--is_initial', default=True)\n",
    "    parser.add_argument('--sampler', default='RL_sampler')\n",
    "    parser.add_argument('--cluster_type', default='kmeans', help='Types of clustering algorithms') # DBSCAN\n",
    "    \n",
    "    # RL-0\n",
    "    parser.add_argument('--threshold_start0', default=[[0.2],[0.2],[0.2]], type=float, \n",
    "                        help='The initial value of the filter threshold for state1 or state3')\n",
    "    parser.add_argument('--RL_step0', default=0.02, type=float, help='The starting epoch of RL for state1 or state3')\n",
    "    parser.add_argument('--RL_start0', default=0, type=int, help='The starting epoch of RL for state1 or state3')\n",
    "    \n",
    "    # RL-1\n",
    "    parser.add_argument('--eps_start', default=0.001, type=float, help='The initial value of the eps for state2')\n",
    "    parser.add_argument('--eps_step', default=0.02, type=float, help='The step size of eps for state2')\n",
    "    parser.add_argument('--min_Pts_start', default=2, type=int, help='The initial value of the min_Pts for state2')\n",
    "    parser.add_argument('--min_Pts_step', default=1, type=int, help='The step size of min_Pts for state2')\n",
    "    \n",
    "    # other arguments\n",
    "    parser.add_argument('--use_cuda', dest='use_cuda', default=True, action='store_true', help='Use cuda')\n",
    "    parser.add_argument('--data_path', default=project_path + '/result/FinEvent result/offline dataset/', type=str, help='Path of features, labels and edges')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--mask_path', default=None, type=str, help='File path that contains the training, validation and test masks')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--log_interval', default=10, type=int, help='Log interval')\n",
    "    \n",
    "    args = parser.parse_args(args=[])  # 解析参数\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d36e98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826bc9e0",
   "metadata": {},
   "source": [
    "## offline FinEvent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21115429",
   "metadata": {
    "code_folding": [
     171
    ]
   },
   "outputs": [],
   "source": [
    "def offline_FinEvent_model(train_i, i,\n",
    "                 args,\n",
    "                 metrics,\n",
    "                 embedding_save_path,\n",
    "                 loss_fn,\n",
    "                 model=None,\n",
    "                 loss_fn_dgi=None):\n",
    "    # step1: make dir for graph i\n",
    "    # ./incremental_0808//embeddings_0403005348/block_xxx\n",
    "    save_path_i = embedding_save_path + '/block_' + str(i)\n",
    "    if not os.path.isdir(save_path_i):\n",
    "        os.mkdir(save_path_i)\n",
    "    \n",
    "    # step2: load data\n",
    "    relation_ids: List[str] = ['entity', 'userid', 'word']\n",
    "    homo_data = create_offline_homodataset(args.data_path, [train_i, i])\n",
    "    multi_r_data = create_multi_relational_graph(args.data_path, relation_ids, [train_i, i])\n",
    "    num_relations = len(multi_r_data)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() and args.use_cuda else 'cpu')\n",
    "    \n",
    "    # input dimension (300 in our paper)\n",
    "    num_dim = homo_data.x.size(0)\n",
    "    feat_dim = homo_data.x.size(1)\n",
    "    \n",
    "    # prepare graph configs for node filtering\n",
    "    if args.is_initial:\n",
    "        print('prepare node configures...')\n",
    "        cal_similarity_node_edge(multi_r_data, homo_data.x, save_path_i)\n",
    "        filter_path = save_path_i\n",
    "    else:\n",
    "        filter_path = args.data_path + str(i)\n",
    "    \n",
    "    if model is None:  # pre-training stage in our paper\n",
    "        # print('Pre-Train Stage...')\n",
    "#         model = MarGNN((feat_dim, args.hidden_dim, args.out_dim, args.heads), \n",
    "#                       num_relations=num_relations, inter_opt=args.inter_opt,is_shared=args.is_shared)\n",
    "        model = HeteGAT_multi((feat_dim, args.hidden_dim, args.out_dim, args.heads), \n",
    "                      num_relations=num_relations, inter_opt=args.inter_opt,is_shared=args.is_shared)\n",
    "    \n",
    "    # define sampler\n",
    "    sampler = MySampler(args.sampler)\n",
    "    # load model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    # initialize RL thresholds\n",
    "    # RL_threshold: [[.5],[.5],[.5]]\n",
    "    RL_thresholds = torch.FloatTensor(args.threshold_start0)\n",
    "    \n",
    "    # define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
    "    \n",
    "    # record training log\n",
    "    message = '\\n------Start initial training /maintaining using block' + str(i) + '------\\n'\n",
    "    print(message)\n",
    "    with open(save_path_i + '/log.txt', 'a') as f:\n",
    "        f.write(message)\n",
    "    \n",
    "    # step12.0: record the highest validation nmi ever got for early stopping\n",
    "    best_vali_nmi = 1e-9\n",
    "    best_epoch = 0\n",
    "    wait = 0\n",
    "    # step12.1: record validation nmi of all epochs before early stop\n",
    "    all_vali_nmi = []\n",
    "    # step12.2: record the time spent in seconds on each batch of all training/maintaining epochs\n",
    "    seconds_train_batches = []\n",
    "    # step12.3: record the time spent in mins on each epoch\n",
    "    mins_train_epochs = []\n",
    "    \n",
    "    # step13: start training------------------------------------------------------------\n",
    "    print('----------------------------------training----------------------------')\n",
    "    for epoch in range(args.n_epochs):\n",
    "        start_epoch = time.time()\n",
    "        losses = []\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for metric in metrics:\n",
    "            metric.reset()\n",
    "        \n",
    "        # Multi-Agent\n",
    "        \n",
    "        # filter neighbor in adbvance to fit with neighbor sampling, return filtered neighbor index\n",
    "        if epoch >= args.RL_start0 and args.sampler == 'RL_sampler':\n",
    "            filtered_multi_r_data = RL_neighbor_filter(multi_r_data, RL_thresholds, filter_path) \n",
    "        else:\n",
    "            filtered_multi_r_data = multi_r_data\n",
    "        \n",
    "        # step13.0: forward\n",
    "        model.train()\n",
    "        \n",
    "        #     data.train_mask, data.val_mask, data.test_mask = gen_offline_masks(len(labels))\n",
    "        train_num_samples, valid_num_samples, test_num_samples = homo_data.train_mask.size(0), homo_data.val_mask.size(0), homo_data.test_mask.size(0)\n",
    "        all_num_samples = train_num_samples + valid_num_samples + test_num_samples\n",
    "        \n",
    "        torch.save(homo_data.train_mask, save_path_i + '/train_mask.pt')\n",
    "        torch.save(homo_data.val_mask, save_path_i + '/valid_mask.pt')\n",
    "        torch.save(homo_data.test_mask, save_path_i + '/test_mask.pt')\n",
    "        \n",
    "        # mini-batch training\n",
    "        num_batches = int(train_num_samples / args.batch_size) + 1\n",
    "        for batch in range(num_batches):\n",
    "            start_batch = time.time()\n",
    "            # split batch\n",
    "            i_start = args.batch_size * batch\n",
    "            i_end = min((batch + 1) * args.batch_size, train_num_samples)\n",
    "            batch_nodes = homo_data.train_mask[i_start:i_end]\n",
    "            batch_labels = homo_data.y[batch_nodes]\n",
    "            \n",
    "            # sampling neighbors of batch nodes\n",
    "            adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx=batch_nodes, sizes=[-1,-1],batch_size=args.batch_size)\n",
    "            \n",
    "            optimizer.zero_grad()  # 将参数置0\n",
    "            \n",
    "            pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "            \n",
    "            loss_outputs = loss_fn(pred, batch_labels)\n",
    "            loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "            losses.append(loss.item())\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # step13.1: metrics\n",
    "            for metric in metrics:\n",
    "                metric(pred, batch_labels, loss_outputs)\n",
    "            if batch % args.log_interval == 0:\n",
    "                message = 'Train: [{}/{} ({:.0f}%)] \\tloss: {:.6f}'.format(batch * args.batch_size, train_num_samples,\n",
    "                          100. * batch / ((train_num_samples // args.batch_size) + 1), np.mean(losses))\n",
    "                for metric in metrics:\n",
    "                    message += '\\t{}: {:.4f}'.format(metric.name(), metric.value())\n",
    "                # print(message)\n",
    "                with open(save_path_i + '.log.txt', 'a') as f:\n",
    "                    f.write(message)\n",
    "                losses = []\n",
    "            \n",
    "            # print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "            del pred, loss_outputs\n",
    "            gc.collect()\n",
    "            \n",
    "            # step13.2: backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_seconds_spent = time.time() - start_batch\n",
    "            seconds_train_batches.append(batch_seconds_spent)\n",
    "            \n",
    "            del loss\n",
    "            gc.collect()\n",
    "        \n",
    "        # step14: print loss\n",
    "        total_loss /= (batch + 1)\n",
    "        message = 'Epoch: {}/{}. Average loss: {:.4f}'.format(epoch, args.n_epochs, total_loss)\n",
    "        \n",
    "        for metric in metrics:\n",
    "            message += '\\t{}: {:.4f}'.format(metric.name(), metric.value())\n",
    "        mins_spent = (time.time() - start_epoch) / 60\n",
    "        message += '\\nThis epoch took {:.2f} mins'.format(mins_spent)\n",
    "        message += '\\n'\n",
    "        print(message)\n",
    "        with open(save_path_i + '/log.txt', 'a') as f:\n",
    "            f.write(message)\n",
    "        mins_train_epochs.append(mins_spent)\n",
    "        \n",
    "        # step15: validation--------------------------------------------------------\n",
    "        print('---------------------validation-------------------------------------')\n",
    "        # inder the representations of all tweets\n",
    "        model.eval()\n",
    "        \n",
    "        # we recommend to forward all nodes and select the validation indices instead\n",
    "        extract_features = torch.FloatTensor([])\n",
    "        num_batches = int(all_num_samples / args.batch_size) + 1\n",
    "        \n",
    "        # all mask are then splited into mini-batch in order\n",
    "        all_mask = torch.arange(0, num_dim, dtype=torch.long)\n",
    "        \n",
    "        for batch in range(num_batches):\n",
    "            start_batch = time.time()\n",
    "            \n",
    "            # split batch\n",
    "            i_start = args.batch_size * batch\n",
    "            i_end = min((batch + 1) * args.batch_size, all_num_samples)\n",
    "            batch_nodes = all_mask[i_start:i_end]\n",
    "            \n",
    "            # sampling neighbors of batch nodes\n",
    "            adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx=batch_nodes, sizes=[-1,-1], batch_size=args.batch_size)\n",
    "            \n",
    "            pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "            \n",
    "            extract_features = torch.cat((extract_features, pred.cpu().detach()), dim=0)\n",
    "            \n",
    "            del pred\n",
    "            gc.collect()\n",
    "        \n",
    "        # evaluate the model: conduct kMeans clustering on the validation and report NMI\n",
    "        validation_nmi = evaluate(extract_features[homo_data.val_mask],\n",
    "                                 homo_data.y,\n",
    "                                 indices=homo_data.val_mask,\n",
    "                                 epoch=epoch,\n",
    "                                 num_isolated_nodes=0,\n",
    "                                 save_path=save_path_i,\n",
    "                                 is_validation=True,\n",
    "                                 cluster_type=args.cluster_type)\n",
    "        all_vali_nmi.append(validation_nmi)\n",
    "        \n",
    "        # step16: early stop\n",
    "        if validation_nmi > best_vali_nmi:\n",
    "            best_vali_nmi = validation_nmi\n",
    "            best_epoch = epoch\n",
    "            wait = 0\n",
    "            # save model\n",
    "            model_path = save_path_i + '/models'\n",
    "            if (epoch == 0) and (not os.path.isdir(model_path)):\n",
    "                os.mkdir(model_path)\n",
    "            p = model_path + '/best.pt'\n",
    "            torch.save(model.state_dict(), p)\n",
    "            print('Best model was at epoch ', str(best_epoch))\n",
    "        else:\n",
    "            wait += 1\n",
    "        if wait >= args.patience:\n",
    "            print('Saved all_mins_spent')\n",
    "            print('Early stopping at epoch ', str(epoch))\n",
    "            print('Best model was at epoch ', str(best_epoch))\n",
    "            break\n",
    "        # end one epoch\n",
    "    \n",
    "    # step17: save all validation nmi\n",
    "    np.save(save_path_i + '/all_vali_nmi.npy', np.asarray(all_vali_nmi))\n",
    "    # save time spent on epochs\n",
    "    np.save(save_path_i + '/mins_train_epochs.npy', np.asarray(mins_train_epochs))\n",
    "    print('Saved mins_train_epochs.')\n",
    "    # save time spent on batches\n",
    "    np.save(save_path_i + '/seconds_train_batches.npy', np.asarray(seconds_train_batches))\n",
    "    print('Saved seconds_train_batches.')\n",
    "    \n",
    "    # step18: load the best model of the current block\n",
    "    best_model_path = save_path_i + '/models/best.pt'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    print('Best model loaded.')\n",
    "    \n",
    "    # del homo_data, multi_r_data\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # test--------------------------------------------------------\n",
    "    print('--------------------test----------------------------')\n",
    "    model.eval()\n",
    "    \n",
    "    # we recommend to forward all nodes and select the validation indices instead\n",
    "    extract_features = torch.FloatTensor([])\n",
    "    num_batches = int(all_num_samples /args.batch_size) + 1\n",
    "    \n",
    "    # all mask are then splited into mini-batch in order\n",
    "    all_mask = torch.arange(0, num_dim, dtype= torch.long)\n",
    "    \n",
    "    for batch in range(num_batches):\n",
    "        start_batch = time.time()\n",
    "        \n",
    "        # split batch\n",
    "        i_start = args.batch_size * batch\n",
    "        i_end = min((batch +1) * args.batch_size, all_num_samples)\n",
    "        batch_nodes = all_mask[i_start:i_end]\n",
    "        batch_labels = homo_data.y[batch_nodes]\n",
    "        \n",
    "        # sampling neighbors of batch nodes\n",
    "        adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx=batch_nodes, sizes=[-1,-1], batch_size=args.batch_size)\n",
    "        \n",
    "        pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "        \n",
    "        extract_features = torch.cat((extract_features, pred.cpu().detach()), dim=0)\n",
    "        del pred\n",
    "        gc.collect()\n",
    "        \n",
    "    save_embeddings(extract_features, save_path_i)\n",
    "    \n",
    "    test_nmi = evaluate(extract_features[homo_data.test_mask],\n",
    "                       homo_data.y,\n",
    "                       indices=homo_data.test_mask,\n",
    "                       epoch=-1,\n",
    "                       num_isolated_nodes=0,\n",
    "                       save_path=save_path_i,\n",
    "                       is_validation=False,\n",
    "                       cluster_type=args.cluster_type)\n",
    "                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f7d87",
   "metadata": {},
   "source": [
    "## run offline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c71060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n",
      "embedding save path:  D:\\PycharmProjects\\GNN_Event_Detection_models/result/FinEvent result/offline dataset//offline_embeddings\n",
      "Batch Size: 100\n",
      "Intra Agg Mode: False\n",
      "Inter Agg Mode: cat_w_avg\n",
      "Reserve node config? True\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'OnlineTripletLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m OnlineTripletLoss(args\u001b[38;5;241m.\u001b[39mmargin, HardestNegativeTripletSelector(args\u001b[38;5;241m.\u001b[39mmargin))  \u001b[38;5;66;03m# margin used for computing tripletloss\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m \u001b[43mOnlineTripletLoss\u001b[49m(args\u001b[38;5;241m.\u001b[39mmargin, RandomNegativeTripletSelector(args\u001b[38;5;241m.\u001b[39mmargin))\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# define metrics\u001b[39;00m\n\u001b[0;32m     34\u001b[0m BCL_metrics \u001b[38;5;241m=\u001b[39m [AverageNonzeroTripletsMetric()]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OnlineTripletLoss' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # define args\n",
    "    args = args_register()\n",
    "    \n",
    "    # check CUDA\n",
    "    print('Using CUDA:', torch.cuda.is_available())\n",
    "    \n",
    "    # create working path\n",
    "    embedding_save_path = args.data_path + '/offline_embeddings'\n",
    "    if embedding_save_path is None:\n",
    "        os.mkdir(embedding_save_path)\n",
    "    print('embedding save path: ', embedding_save_path)\n",
    "        \n",
    "    # record hyper-parameters\n",
    "    with open(embedding_save_path + '/args.txt', 'w') as f:\n",
    "        json.dump(args.__dict__, f, indent=2)  # __dict__将模型参数保存成字典形式；indent缩进打印\n",
    "    \n",
    "    print('Batch Size:', args.batch_size)\n",
    "    print('Intra Agg Mode:', args.is_shared)\n",
    "    print('Inter Agg Mode:', args.inter_opt)\n",
    "    print('Reserve node config?', args.is_initial)\n",
    "    \n",
    "    # load number of message in each blocks\n",
    "    # e.g. data_split = [  500  ,   100, ...,  100]\n",
    "    #                    block_0  block_1    block_n\n",
    "    # define loss function，调用forward(embeddings, labels)方法，最终loss返回单个值\n",
    "    # contrastive loss in our paper\n",
    "    if args.use_hardest_neg:\n",
    "        # HardestNegativeTripletSelector返回某标签下ith元素和jth元素，其最大loss对应的其他标签元素索引\n",
    "        loss_fn = OnlineTripletLoss(args.margin, HardestNegativeTripletSelector(args.margin))  # margin used for computing tripletloss\n",
    "    else:\n",
    "        loss_fn = OnlineTripletLoss(args.margin, RandomNegativeTripletSelector(args.margin))\n",
    "    # define metrics\n",
    "    BCL_metrics = [AverageNonzeroTripletsMetric()]\n",
    "    # define detection stage\n",
    "    Streaming = FinEvent(args)\n",
    "    # pre-train stage: train on initial graph\n",
    "    train_i = 0\n",
    "    model, RL_thresholds = offline_FinEvent_model(train_i=train_i,\n",
    "                                        args=args,\n",
    "                                        i=0,\n",
    "                                        metrics=BCL_metrics,\n",
    "                                        embedding_save_path=embedding_save_path,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee907c5",
   "metadata": {},
   "source": [
    "# Run_FinEvent_Cross-lingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8e4c0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "from time import localtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f7b8d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_register():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_epochs', default=50, type=int, help='Number of initial-training/maintenance-training epochs.')\n",
    "    parser.add_argument('--window_size', default=3, type=int, help='Maintain the model after predicting window_size blocks.')\n",
    "    parser.add_argument('--patience', default=5, type=int, help='Early stop if performance did not improve in the last patience epochs.')\n",
    "    parser.add_argument('--margin', default=3., type=float, help='Margin for computing triplet losses')\n",
    "    parser.add_argument('--lr', default=1e-3, type=float, help='Learning rate')\n",
    "    \n",
    "    parser.add_argument('--batch_size', default=100, type=int, help='Batch size (number of nodes sampled to compute triplet loss in each batch)')\n",
    "    parser.add_argument('--hidden_dim', default=128, type=int, help='Hidden dimension')\n",
    "    parser.add_argument('--out_dim', default=64, type=int, help='Output dimension of tweet representations')\n",
    "    parser.add_argument('--heads', default=4, type=int, help='Number of heads used in GAT')\n",
    "    parser.add_argument('--validation_percent', default=0.2, type=float, help='Percentage of validation nodes(tweets)')\n",
    "    \n",
    "    parser.add_argument('--use_hardest_neg', dest='use_hardest_neg', default=False, action='store_true', \n",
    "                       help='If true, use hardest negative messages to form triplets. Otherwise use random ones')\n",
    "    parser.add_argument('--is_shared', default=False)\n",
    "    parser.add_argument('--inter_opt', default='cat_w_avg')\n",
    "    parser.add_argument('--is_initial', default=False)\n",
    "    parser.add_argument('--sampler', default='RL_sampler')\n",
    "    parser.add_argument('--cluster_type', default='kmeans', help='Types of clustering algorithms')  # DBSCAN\n",
    "    \n",
    "    # RL-0\n",
    "    parser.add_argument('--threshold_start0', default=[[0.5],[0.5],[0.5]], type=float, \n",
    "                        help='The initial value of the filter threshold for state1 or state3')\n",
    "    parser.add_argument('--RL_step0', default=0.02, type=float, help='The step size of RL for state1 or state3')\n",
    "    parser.add_argument('--RL_start0', default=0, type=int, help='The starting epoch of RL for state1 or state3')\n",
    "    \n",
    "    # RL-1\n",
    "    parser.add_argument('--eps_start', default=0.001, type=float, help='The initial value of the eps for state2')\n",
    "    parser.add_argument('--eps_step', default=0.02, type=float, help='The step size of eps for state2')\n",
    "    parser.add_argument('--min_Pts_start', default=2, type=int, help='The initial value of the min_Pts for state2')\n",
    "    parser.add_argument('--min_Pts_step', default=1, type=int, help='The step size of min_Pts for state2')\n",
    "    \n",
    "    # other arguments\n",
    "    parser.add_argument('--use_cuda', dest='use_cuda', default=True, action='store_true', help='Use cuda')\n",
    "    parser.add_argument('--data_path', default='./incremental_0502/', type=str, help='Path of features, labels and edges')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--mask_path', default=None, type=str, help='File path that contains the training, validation and test masks')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--resume_path', default='incremental_cross_English_68841/', type=str, \n",
    "                       help='Resume trained model and directly used to inference')\n",
    "    parser.add_argument('--log_interval', default=10, type=int, help='Log interval')\n",
    "    args = parser.parse_args(args=[])  # 解析参数\n",
    "    \n",
    "    return args"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "480px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
